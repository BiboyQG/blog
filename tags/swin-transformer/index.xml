<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>Swin Transformer on Banghao&#39;s Blog</title>
    <link>https://biboyqg.github.io/blog/tags/swin-transformer/</link>
    <description>Recent content in Swin Transformer on Banghao&#39;s Blog</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Fri, 15 Mar 2024 05:21:09 -0500</lastBuildDate>
    <atom:link href="https://biboyqg.github.io/blog/tags/swin-transformer/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>CATseg: A complete walk through of the model architecture</title>
      <link>https://biboyqg.github.io/blog/blog/catseg/</link>
      <pubDate>Fri, 15 Mar 2024 05:21:09 -0500</pubDate>
      <guid>https://biboyqg.github.io/blog/blog/catseg/</guid>
      <description>1. Model Architecture setup and evaluation data flow(for ade150k) CATSeg setup:
backbone: D2SwinTransformer -&amp;gt; Swintransformer -&amp;gt; BasicLayer(2) -&amp;gt; SwinTransformerBlock -&amp;gt; WindowAttention
sem_seg_head: CATSegHead.from_config -&amp;gt; CATSegPredictor -&amp;gt;
Load CLIP model -&amp;gt; Load text templates -&amp;gt; class_embeddings(self.class_texts, prompt_templates, clip_model) -&amp;gt; for each class:
bpe encode classname in different templates and save results in variable texts (80(number of templates), 77(number of sentence length)). CLIP encode texts : texts go through token_embedding(nn.Embedding) (80,77,768(hidden_dim)) texts go through a 12 layers of ResidualAttentionBlock (80,77,768) take features of texts from the eot_token (80,768) do the above for all classes (150(number of test classes),80,768)</description>
    </item>
  </channel>
</rss>
