<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>Quantization on Banghao&#39;s Blog</title>
    <link>https://banghao.live/tags/quantization/</link>
    <description>Recent content in Quantization on Banghao&#39;s Blog</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Fri, 26 Apr 2024 15:32:56 -0500</lastBuildDate>
    <atom:link href="https://banghao.live/tags/quantization/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Meeting Discussion (4)</title>
      <link>https://banghao.live/blog/4/</link>
      <pubDate>Fri, 26 Apr 2024 15:32:56 -0500</pubDate>
      <guid>https://banghao.live/blog/4/</guid>
      <description>1. The strcuture of the CenterPoint-Vexel model CenterPoint( (vfe): MeanVFE() (backbone_3d): VoxelResBackBone8x( (conv_input): SparseSequential( (0): SubMConv3d(5, 16, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm) (1): BatchNorm1d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True) (2): ReLU() ) (conv1): SparseSequential( (0): SparseBasicBlock( (conv1): SubMConv3d(16, 16, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm) (bn1): BatchNorm1d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True) (relu): ReLU() (conv2): SubMConv3d(16, 16, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.</description>
    </item>
    <item>
      <title>Meeting Discussion (3)</title>
      <link>https://banghao.live/blog/3/</link>
      <pubDate>Tue, 02 Apr 2024 18:18:50 -0500</pubDate>
      <guid>https://banghao.live/blog/3/</guid>
      <description>What has been done? This week&amp;rsquo;s work:
Setup nuScenes training and validation dataset for MMDetection3D framework. Setup waymo training and validation dataset for MMDetection3D framework. Wrote API for PTQ under pytorch-quantization framework. (Now just need model and dataloader definition) Complete walkthrough of CAT-Seg, a SOTA Open Vocabulary Segmentation (OVS) model. What to discuss? Is this quantization way appropriate? Any advice on the changing of model structure (CAT-Seg)? What&amp;rsquo;s next (in the order of priority) Modify pytorch-quantization source code to implement weight-only quantization (below is a potential way):</description>
    </item>
    <item>
      <title>Quantization on CenterPoint</title>
      <link>https://banghao.live/blog/quant/</link>
      <pubDate>Mon, 01 Apr 2024 16:32:18 -0500</pubDate>
      <guid>https://banghao.live/blog/quant/</guid>
      <description>Take mmdetection as an example First find the Runner class: This is the place where the build of the model is completed:
class Runner: def __init__(...): ... ... self.model = self.build_model(model) # wrap model self.model = self.wrap_model( self.cfg.get(&amp;#39;model_wrapper_cfg&amp;#39;), self.model) # get model name from the model class if hasattr(self.model, &amp;#39;module&amp;#39;): self._model_name = self.model.module.__class__.__name__ else: self._model_name = self.model.__class__.__name__ ... ... Learn about how pytorch-quantization works by diving into its source code: Code about the quantization function respect to a specific Pytorch model as input: quant_utils.</description>
    </item>
  </channel>
</rss>
