<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>Banghao&#39;s Blog</title>
    <link>https://banghao.live/</link>
    <description>Recent content on Banghao&#39;s Blog</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Sun, 05 May 2024 16:18:51 -0500</lastBuildDate>
    <atom:link href="https://banghao.live/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>IoT-Enabled Home Security Camera</title>
      <link>https://banghao.live/blog/camera/</link>
      <pubDate>Sun, 05 May 2024 16:18:51 -0500</pubDate>
      <guid>https://banghao.live/blog/camera/</guid>
      <description>Video GitHub
1. Motivation Facial recognition technology has become prevalent in all areas of life. Whether you work in security, law enforcement, or manufacture personal devices, the presence of facial recognition for various purposes is evident. Our project seeks to dive into this increasingly common technology and apply it to a place that needs upgrades, such as banks. Many banks are on old applications or using outdated technology, limiting the effectiveness of their work.</description>
    </item>
    <item>
      <title>Meeting Discussion (6)</title>
      <link>https://banghao.live/blog/6/</link>
      <pubDate>Thu, 02 May 2024 17:04:02 -0500</pubDate>
      <guid>https://banghao.live/blog/6/</guid>
      <description>1. Table of Contents In-depth Memory Usage Visualization
Ideas about how to implement quantization of sparse conv3d
Ideas about how to implement SmoothQuant operation on conv2d
2. Large Chunk GPU Memory Usage Overview Data loader Backbone 3d Backbone 3d -&amp;gt; Backbone 2d Backbone 2d Head Below are structure for each major chunk:
Data Loader Backbone 3d 3d feature to 2d feature Backbone 2d Head 3. How to implement quantization of sparse conv3d?</description>
    </item>
    <item>
      <title>Meeting Discussion (5)</title>
      <link>https://banghao.live/blog/5/</link>
      <pubDate>Wed, 01 May 2024 16:48:28 -0500</pubDate>
      <guid>https://banghao.live/blog/5/</guid>
      <description>1. Accuracy graph under diffrerent quantization metrics: As we can observe from both graphs, activation is clearly influced more by quantization.
2. Max value within the layers In the first graph, we can see that the max value within the weigh ranges from 0.1 to 2.94, while in the second graph, we can find an interesting max value pattern, with its value ranging from 8 to 53.74, which also explains why activation is influenced more by quantization.</description>
    </item>
    <item>
      <title>Meeting Discussion (4)</title>
      <link>https://banghao.live/blog/4/</link>
      <pubDate>Fri, 26 Apr 2024 15:32:56 -0500</pubDate>
      <guid>https://banghao.live/blog/4/</guid>
      <description>1. The strcuture of the CenterPoint-Vexel model CenterPoint( (vfe): MeanVFE() (backbone_3d): VoxelResBackBone8x( (conv_input): SparseSequential( (0): SubMConv3d(5, 16, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm) (1): BatchNorm1d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True) (2): ReLU() ) (conv1): SparseSequential( (0): SparseBasicBlock( (conv1): SubMConv3d(16, 16, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm) (bn1): BatchNorm1d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True) (relu): ReLU() (conv2): SubMConv3d(16, 16, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.</description>
    </item>
    <item>
      <title>Meeting Discussion (3)</title>
      <link>https://banghao.live/blog/3/</link>
      <pubDate>Tue, 02 Apr 2024 18:18:50 -0500</pubDate>
      <guid>https://banghao.live/blog/3/</guid>
      <description>What has been done? This week&amp;rsquo;s work:
Setup nuScenes training and validation dataset for MMDetection3D framework. Setup waymo training and validation dataset for MMDetection3D framework. Wrote API for PTQ under pytorch-quantization framework. (Now just need model and dataloader definition) Complete walkthrough of CAT-Seg, a SOTA Open Vocabulary Segmentation (OVS) model. What to discuss? Is this quantization way appropriate? Any advice on the changing of model structure (CAT-Seg)? What&amp;rsquo;s next (in the order of priority) Modify pytorch-quantization source code to implement weight-only quantization (below is a potential way):</description>
    </item>
    <item>
      <title>Quantization on CenterPoint</title>
      <link>https://banghao.live/blog/quant/</link>
      <pubDate>Mon, 01 Apr 2024 16:32:18 -0500</pubDate>
      <guid>https://banghao.live/blog/quant/</guid>
      <description>Take mmdetection as an example First find the Runner class: This is the place where the build of the model is completed:
class Runner: def __init__(...): ... ... self.model = self.build_model(model) # wrap model self.model = self.wrap_model( self.cfg.get(&amp;#39;model_wrapper_cfg&amp;#39;), self.model) # get model name from the model class if hasattr(self.model, &amp;#39;module&amp;#39;): self._model_name = self.model.module.__class__.__name__ else: self._model_name = self.model.__class__.__name__ ... ... Learn about how pytorch-quantization works by diving into its source code: Code about the quantization function respect to a specific Pytorch model as input: quant_utils.</description>
    </item>
    <item>
      <title>Daily Log</title>
      <link>https://banghao.live/blog/log/</link>
      <pubDate>Wed, 20 Mar 2024 06:35:10 -0500</pubDate>
      <guid>https://banghao.live/blog/log/</guid>
      <description>3.12 Managed to understand the whole code base of the CLIP repo from OpenAI. Planned to take a look at CAT-Seg: Cost Aggregation for Open-Vocabulary Semantic Segmentation, to understand how to implement Open-Vocabulary Segmentation (OVS) using CLIP.
3.13 1. DETR Got a basic understanding of DETR, which is an awesome end-to-end 2D object detection architecture, with its downside lies in:
Long training period Difficulty of detecting small objects but has advantages in:</description>
    </item>
    <item>
      <title>CATseg: A complete walk through of the model architecture</title>
      <link>https://banghao.live/blog/catseg/</link>
      <pubDate>Fri, 15 Mar 2024 05:21:09 -0500</pubDate>
      <guid>https://banghao.live/blog/catseg/</guid>
      <description>1. Model Architecture setup and evaluation data flow(for ade150k) CATSeg setup:
backbone: D2SwinTransformer -&amp;gt; Swintransformer -&amp;gt; BasicLayer(2) -&amp;gt; SwinTransformerBlock -&amp;gt; WindowAttention
sem_seg_head: CATSegHead.from_config -&amp;gt; CATSegPredictor -&amp;gt;
Load CLIP model -&amp;gt; Load text templates -&amp;gt; class_embeddings(self.class_texts, prompt_templates, clip_model) -&amp;gt; for each class:
bpe encode classname in different templates and save results in variable texts (80(number of templates), 77(number of sentence length)). CLIP encode texts : texts go through token_embedding(nn.Embedding) (80,77,768(hidden_dim)) texts go through a 12 layers of ResidualAttentionBlock (80,77,768) take features of texts from the eot_token (80,768) do the above for all classes (150(number of test classes),80,768)</description>
    </item>
    <item>
      <title>Argparse: a user-friendly tool to write CLI interface</title>
      <link>https://banghao.live/blog/argparse/</link>
      <pubDate>Fri, 08 Mar 2024 07:38:30 -0500</pubDate>
      <guid>https://banghao.live/blog/argparse/</guid>
      <description>1. Introduction Hello fellows! Today I&amp;rsquo;m excited to share insights about the argparse module, a robust and intuitive tool for creating command-line interfaces in Python. What makes argparse particularly fascinating to me is its ability to enable users to quickly leverage Python scripts with custom configurations and functionalities, without the need to dive into the underlying source code. This feature of argparse has captured my interest and again, showcasing its value in making Python files reusable and accessible for diverse applications.</description>
    </item>
    <item>
      <title>Real-time Object Recognition in Chess: Personalized Tuning and Hardware Acceleration</title>
      <link>https://banghao.live/blog/chess/</link>
      <pubDate>Sat, 05 Aug 2023 16:53:11 -0500</pubDate>
      <guid>https://banghao.live/blog/chess/</guid>
      <description>1. Selected and customized the YOLOv5 model for Chinese chess annotation data. 2. Conducted testing and analysis of the model. The results indicated exceptional accuracy in recognition capabilities. However, a significant shortfall was identified in terms of efficiency, with the model taking approximately 6 seconds to process a single image.
3. Implemented model optimization. We substitute the YOLOv5 model with a more lightweight variant, YOLOv5-lite and convert the model into the ONNX format to leverage hardware acceleration, thereby enhancing computational efficiency.</description>
    </item>
  </channel>
</rss>
