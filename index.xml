<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>Banghao&#39;s Blog</title>
    <link>https://banghao.live/</link>
    <description>Recent content on Banghao&#39;s Blog</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Wed, 20 Mar 2024 06:35:10 -0500</lastBuildDate>
    <atom:link href="https://banghao.live/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Daily Log</title>
      <link>https://banghao.live/blog/log/</link>
      <pubDate>Wed, 20 Mar 2024 06:35:10 -0500</pubDate>
      <guid>https://banghao.live/blog/log/</guid>
      <description>3.12 Managed to understand the whole code base of the CLIP repo from OpenAI. Planned to take a look at CAT-Seg: Cost Aggregation for Open-Vocabulary Semantic Segmentation, to understand how to implement Open-Vocabulary Segmentation (OVS) using CLIP.
3.13 1. DETR Got a basic understanding of DETR, which is an awesome end-to-end 2D object detection architecture, with its downside lies in:
Long training period Difficulty of detecting small objects but has advantages in:</description>
    </item>
    <item>
      <title>CATseg: A complete walk through of the model architecture</title>
      <link>https://banghao.live/blog/catseg/</link>
      <pubDate>Fri, 15 Mar 2024 05:21:09 -0500</pubDate>
      <guid>https://banghao.live/blog/catseg/</guid>
      <description>1. Model Architecture setup and evaluation data flow(for ade150k) CATSeg setup:
backbone: D2SwinTransformer -&amp;gt; Swintransformer -&amp;gt; BasicLayer(2) -&amp;gt; SwinTransformerBlock -&amp;gt; WindowAttention
sem_seg_head: CATSegHead.from_config -&amp;gt; CATSegPredictor -&amp;gt;
Load CLIP model -&amp;gt; Load text templates -&amp;gt; class_embeddings(self.class_texts, prompt_templates, clip_model) -&amp;gt; for each class:
bpe encode classname in different templates and save results in variable texts (80(number of templates), 77(number of sentence length)). CLIP encode texts : texts go through token_embedding(nn.Embedding) (80,77,768(hidden_dim)) texts go through a 12 layers of ResidualAttentionBlock (80,77,768) take features of texts from the eot_token (80,768) do the above for all classes (150(number of test classes),80,768)</description>
    </item>
    <item>
      <title>argparse: A user-friendly tool to write CLI interface</title>
      <link>https://banghao.live/blog/argparse/</link>
      <pubDate>Fri, 08 Mar 2024 07:38:30 -0500</pubDate>
      <guid>https://banghao.live/blog/argparse/</guid>
      <description>1. Introduction Hello fellows! Today I&amp;rsquo;m excited to share insights about the argparse module, a robust and intuitive tool for creating command-line interfaces in Python. What makes argparse particularly fascinating to me is its ability to enable users to quickly leverage Python scripts with custom configurations and functionalities, without the need to dive into the underlying source code. This feature of argparse has captured my interest and again, showcasing its value in making Python files reusable and accessible for diverse applications.</description>
    </item>
  </channel>
</rss>
