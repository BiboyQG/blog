<!DOCTYPE html>
<html lang="en" dir="auto">

<head><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="index, follow">
<title>Meeting Discussion (4) | Banghao&#39;s Blog</title>
<meta name="keywords" content="meeting-discussions, research, Quantization">
<meta name="description" content="1. Table of Contents The strcuture of the CenterPoint-Vexel model: ✅ Inference time of each layer: ✅ Memory usage of each layer: ✅ Storage usage of each layer: ✅ Quantization of the model: ✅ 2. The strcuture of the CenterPoint-Vexel model CenterPoint( (vfe): MeanVFE() (backbone_3d): VoxelResBackBone8x( (conv_input): SparseSequential( (0): SubMConv3d(5, 16, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm) (1): BatchNorm1d(16, eps=0.">
<meta name="author" content="Banghao Chi">
<link rel="canonical" href="https://banghao.live/blog/4/">
<link crossorigin="anonymous" href="/assets/css/stylesheet.8d6d0999b7a3d50c6d5a00541fc8078c4695a82720ad160b4078dab1d4edf114.css" integrity="sha256-jW0Jmbej1QxtWgBUH8gHjEaVqCcgrRYLQHjasdTt8RQ=" rel="preload stylesheet" as="style">
<link rel="icon" href="https://banghao.live/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="https://banghao.live/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="https://banghao.live/favicon-32x32.png">
<link rel="apple-touch-icon" href="https://banghao.live/apple-touch-icon.png">
<link rel="mask-icon" href="https://banghao.live/safari-pinned-tab.svg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<link rel="alternate" hreflang="en" href="https://banghao.live/blog/4/">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
    <style>
        @media (prefers-color-scheme: dark) {
            :root {
                --theme: rgb(29, 30, 32);
                --entry: rgb(46, 46, 51);
                --primary: rgb(218, 218, 219);
                --secondary: rgb(155, 156, 157);
                --tertiary: rgb(65, 66, 68);
                --content: rgb(196, 196, 197);
                --code-block-bg: rgb(46, 46, 51);
                --code-bg: rgb(55, 56, 62);
                --border: rgb(51, 51, 51);
            }

            .list {
                background: var(--theme);
            }

            .list:not(.dark)::-webkit-scrollbar-track {
                background: 0 0;
            }

            .list:not(.dark)::-webkit-scrollbar-thumb {
                border-color: var(--theme);
            }
        }

    </style>
</noscript><meta property="og:title" content="Meeting Discussion (4)" />
<meta property="og:description" content="1. Table of Contents The strcuture of the CenterPoint-Vexel model: ✅ Inference time of each layer: ✅ Memory usage of each layer: ✅ Storage usage of each layer: ✅ Quantization of the model: ✅ 2. The strcuture of the CenterPoint-Vexel model CenterPoint( (vfe): MeanVFE() (backbone_3d): VoxelResBackBone8x( (conv_input): SparseSequential( (0): SubMConv3d(5, 16, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm) (1): BatchNorm1d(16, eps=0." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://banghao.live/blog/4/" /><meta property="article:section" content="blog" />
<meta property="article:published_time" content="2024-04-26T15:32:56-05:00" />
<meta property="article:modified_time" content="2024-04-26T15:32:56-05:00" />

<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="Meeting Discussion (4)"/>
<meta name="twitter:description" content="1. Table of Contents The strcuture of the CenterPoint-Vexel model: ✅ Inference time of each layer: ✅ Memory usage of each layer: ✅ Storage usage of each layer: ✅ Quantization of the model: ✅ 2. The strcuture of the CenterPoint-Vexel model CenterPoint( (vfe): MeanVFE() (backbone_3d): VoxelResBackBone8x( (conv_input): SparseSequential( (0): SubMConv3d(5, 16, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm) (1): BatchNorm1d(16, eps=0."/>


<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [
    {
      "@type": "ListItem",
      "position":  1 ,
      "name": "Blogs",
      "item": "https://banghao.live/blog/"
    }, 
    {
      "@type": "ListItem",
      "position":  2 ,
      "name": "Meeting Discussion (4)",
      "item": "https://banghao.live/blog/4/"
    }
  ]
}
</script>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "Meeting Discussion (4)",
  "name": "Meeting Discussion (4)",
  "description": "1. Table of Contents The strcuture of the CenterPoint-Vexel model: ✅ Inference time of each layer: ✅ Memory usage of each layer: ✅ Storage usage of each layer: ✅ Quantization of the model: ✅ 2. The strcuture of the CenterPoint-Vexel model CenterPoint( (vfe): MeanVFE() (backbone_3d): VoxelResBackBone8x( (conv_input): SparseSequential( (0): SubMConv3d(5, 16, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm) (1): BatchNorm1d(16, eps=0.",
  "keywords": [
    "meeting-discussions", "research", "Quantization"
  ],
  "articleBody": "1. Table of Contents The strcuture of the CenterPoint-Vexel model: ✅ Inference time of each layer: ✅ Memory usage of each layer: ✅ Storage usage of each layer: ✅ Quantization of the model: ✅ 2. The strcuture of the CenterPoint-Vexel model CenterPoint( (vfe): MeanVFE() (backbone_3d): VoxelResBackBone8x( (conv_input): SparseSequential( (0): SubMConv3d(5, 16, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm) (1): BatchNorm1d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True) (2): ReLU() ) (conv1): SparseSequential( (0): SparseBasicBlock( (conv1): SubMConv3d(16, 16, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm) (bn1): BatchNorm1d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True) (relu): ReLU() (conv2): SubMConv3d(16, 16, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm) (bn2): BatchNorm1d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True) ) (1): SparseBasicBlock( (conv1): SubMConv3d(16, 16, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm) (bn1): BatchNorm1d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True) (relu): ReLU() (conv2): SubMConv3d(16, 16, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm) (bn2): BatchNorm1d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True) ) ) (conv2): SparseSequential( (0): SparseSequential( (0): SparseConv3d(16, 32, kernel_size=[3, 3, 3], stride=[2, 2, 2], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm) (1): BatchNorm1d(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True) (2): ReLU() ) (1): SparseBasicBlock( (conv1): SubMConv3d(32, 32, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm) (bn1): BatchNorm1d(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True) (relu): ReLU() (conv2): SubMConv3d(32, 32, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm) (bn2): BatchNorm1d(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True) ) (2): SparseBasicBlock( (conv1): SubMConv3d(32, 32, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm) (bn1): BatchNorm1d(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True) (relu): ReLU() (conv2): SubMConv3d(32, 32, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm) (bn2): BatchNorm1d(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True) ) ) (conv3): SparseSequential( (0): SparseSequential( (0): SparseConv3d(32, 64, kernel_size=[3, 3, 3], stride=[2, 2, 2], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm) (1): BatchNorm1d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True) (2): ReLU() ) (1): SparseBasicBlock( (conv1): SubMConv3d(64, 64, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm) (bn1): BatchNorm1d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True) (relu): ReLU() (conv2): SubMConv3d(64, 64, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm) (bn2): BatchNorm1d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True) ) (2): SparseBasicBlock( (conv1): SubMConv3d(64, 64, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm) (bn1): BatchNorm1d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True) (relu): ReLU() (conv2): SubMConv3d(64, 64, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm) (bn2): BatchNorm1d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True) ) ) (conv4): SparseSequential( (0): SparseSequential( (0): SparseConv3d(64, 128, kernel_size=[3, 3, 3], stride=[2, 2, 2], padding=[0, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm) (1): BatchNorm1d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True) (2): ReLU() ) (1): SparseBasicBlock( (conv1): SubMConv3d(128, 128, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm) (bn1): BatchNorm1d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True) (relu): ReLU() (conv2): SubMConv3d(128, 128, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm) (bn2): BatchNorm1d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True) ) (2): SparseBasicBlock( (conv1): SubMConv3d(128, 128, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm) (bn1): BatchNorm1d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True) (relu): ReLU() (conv2): SubMConv3d(128, 128, kernel_size=[3, 3, 3], stride=[1, 1, 1], padding=[1, 1, 1], dilation=[1, 1, 1], output_padding=[0, 0, 0], algo=ConvAlgo.MaskImplicitGemm) (bn2): BatchNorm1d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True) ) ) (conv_out): SparseSequential( (0): SparseConv3d(128, 128, kernel_size=[3, 1, 1], stride=[2, 1, 1], padding=[0, 0, 0], dilation=[1, 1, 1], output_padding=[0, 0, 0], bias=False, algo=ConvAlgo.MaskImplicitGemm) (1): BatchNorm1d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True) (2): ReLU() ) ) (map_to_bev_module): HeightCompression() (pfe): None (backbone_2d): BaseBEVBackbone( (blocks): ModuleList( (0): Sequential( (0): ZeroPad2d((1, 1, 1, 1)) (1): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), bias=False) (2): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True) (3): ReLU() (4): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (5): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True) (6): ReLU() (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (8): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True) (9): ReLU() (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (11): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True) (12): ReLU() (13): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (14): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True) (15): ReLU() (16): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (17): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True) (18): ReLU() ) (1): Sequential( (0): ZeroPad2d((1, 1, 1, 1)) (1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), bias=False) (2): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True) (3): ReLU() (4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (5): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True) (6): ReLU() (7): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (8): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True) (9): ReLU() (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (11): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True) (12): ReLU() (13): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (14): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True) (15): ReLU() (16): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (17): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True) (18): ReLU() ) ) (deblocks): ModuleList( (0): Sequential( (0): ConvTranspose2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False) (1): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True) (2): ReLU() ) (1): Sequential( (0): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2), bias=False) (1): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True) (2): ReLU() ) ) ) (dense_head): CenterHead( (shared_conv): Sequential( (0): Conv2d(512, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (2): ReLU() ) (heads_list): ModuleList( (0): SeparateHead( (center): Sequential( (0): Sequential( (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (2): ReLU() ) (1): Conv2d(64, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) ) (center_z): Sequential( (0): Sequential( (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (2): ReLU() ) (1): Conv2d(64, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) ) (dim): Sequential( (0): Sequential( (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (2): ReLU() ) (1): Conv2d(64, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) ) (rot): Sequential( (0): Sequential( (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (2): ReLU() ) (1): Conv2d(64, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) ) (vel): Sequential( (0): Sequential( (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (2): ReLU() ) (1): Conv2d(64, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) ) (hm): Sequential( (0): Sequential( (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (2): ReLU() ) (1): Conv2d(64, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) ) ) (1-2): 2 x SeparateHead( (center): Sequential( (0): Sequential( (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (2): ReLU() ) (1): Conv2d(64, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) ) (center_z): Sequential( (0): Sequential( (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (2): ReLU() ) (1): Conv2d(64, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) ) (dim): Sequential( (0): Sequential( (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (2): ReLU() ) (1): Conv2d(64, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) ) (rot): Sequential( (0): Sequential( (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (2): ReLU() ) (1): Conv2d(64, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) ) (vel): Sequential( (0): Sequential( (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (2): ReLU() ) (1): Conv2d(64, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) ) (hm): Sequential( (0): Sequential( (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (2): ReLU() ) (1): Conv2d(64, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) ) ) (3): SeparateHead( (center): Sequential( (0): Sequential( (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (2): ReLU() ) (1): Conv2d(64, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) ) (center_z): Sequential( (0): Sequential( (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (2): ReLU() ) (1): Conv2d(64, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) ) (dim): Sequential( (0): Sequential( (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (2): ReLU() ) (1): Conv2d(64, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) ) (rot): Sequential( (0): Sequential( (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (2): ReLU() ) (1): Conv2d(64, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) ) (vel): Sequential( (0): Sequential( (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (2): ReLU() ) (1): Conv2d(64, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) ) (hm): Sequential( (0): Sequential( (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (2): ReLU() ) (1): Conv2d(64, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) ) ) (4-5): 2 x SeparateHead( (center): Sequential( (0): Sequential( (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (2): ReLU() ) (1): Conv2d(64, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) ) (center_z): Sequential( (0): Sequential( (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (2): ReLU() ) (1): Conv2d(64, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) ) (dim): Sequential( (0): Sequential( (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (2): ReLU() ) (1): Conv2d(64, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) ) (rot): Sequential( (0): Sequential( (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (2): ReLU() ) (1): Conv2d(64, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) ) (vel): Sequential( (0): Sequential( (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (2): ReLU() ) (1): Conv2d(64, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) ) (hm): Sequential( (0): Sequential( (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (2): ReLU() ) (1): Conv2d(64, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) ) ) ) (hm_loss_func): FocalLossCenterNet() (reg_loss_func): RegLossCenterNet() ) (point_head): None (roi_head): None ) Conclusion: compared with normal 2D object detection algorithm’s used layers, LiDAR-based 3D object detection utilize layers like SparseConv3d and SubMConv3d to implement 3D backbone. Other layers are regular.\n3. Inference time of each layer With the use of Profiler: But what we get right here is the layer name of the inner framework, i.e., the function name of C language. Therefore, I write some simple codes to get the consuming of time of each Pytorch layer.\nWith the use of customized code: We get top 20 time-consuming Pytorch layer:\n2024-04-09 09:47:53,138 INFO \u003cclass 'torch.nn.modules.conv.Conv2d'\u003e: 0.07607173919677734 seconds 2024-04-09 09:47:53,139 INFO \u003cclass 'spconv.pytorch.conv.SubMConv3d'\u003e: 0.058701515197753906 seconds 2024-04-09 09:47:53,139 INFO \u003cclass 'spconv.pytorch.conv.SubMConv3d'\u003e: 0.038175344467163086 seconds 2024-04-09 09:47:53,139 INFO \u003cclass 'spconv.pytorch.conv.SubMConv3d'\u003e: 0.030804872512817383 seconds 2024-04-09 09:47:53,139 INFO \u003cclass 'spconv.pytorch.conv.SparseConv3d'\u003e: 0.025530099868774414 seconds 2024-04-09 09:47:53,139 INFO \u003cclass 'spconv.pytorch.conv.SparseConv3d'\u003e: 0.02077198028564453 seconds 2024-04-09 09:47:53,139 INFO \u003cclass 'torch.nn.modules.conv.ConvTranspose2d'\u003e: 0.020176410675048828 seconds 2024-04-09 09:47:53,139 INFO \u003cclass 'spconv.pytorch.conv.SparseConv3d'\u003e: 0.016696453094482422 seconds 2024-04-09 09:47:53,139 INFO \u003cclass 'torch.nn.modules.conv.ConvTranspose2d'\u003e: 0.014063358306884766 seconds 2024-04-09 09:47:53,139 INFO \u003cclass 'spconv.pytorch.conv.SubMConv3d'\u003e: 0.014019966125488281 seconds 2024-04-09 09:47:53,139 INFO \u003cclass 'pcdet.models.backbones_3d.vfe.mean_vfe.MeanVFE'\u003e: 0.012219667434692383 seconds 2024-04-09 09:47:53,139 INFO \u003cclass 'pcdet.models.detectors.centerpoint.CenterPoint'\u003e: 0.01217341423034668 seconds 2024-04-09 09:47:53,139 INFO \u003cclass 'torch.nn.modules.conv.Conv2d'\u003e: 0.009574413299560547 seconds 2024-04-09 09:47:53,139 INFO \u003cclass 'pcdet.models.backbones_2d.map_to_bev.height_compression.HeightCompression'\u003e: 0.006260395050048828 seconds 2024-04-09 09:47:53,139 INFO \u003cclass 'spconv.pytorch.conv.SparseConv3d'\u003e: 0.005869150161743164 seconds 2024-04-09 09:47:53,139 INFO \u003cclass 'torch.nn.modules.conv.Conv2d'\u003e: 0.003749370574951172 seconds 2024-04-09 09:47:53,139 INFO \u003cclass 'torch.nn.modules.conv.Conv2d'\u003e: 0.003445148468017578 seconds 2024-04-09 09:47:53,139 INFO \u003cclass 'torch.nn.modules.conv.Conv2d'\u003e: 0.0028769969940185547 seconds That is to say, the major time-consuming layer should beConv2d, ConvTransposed2d, SubMConv3d, and SparseConv3d, which means that we can start from quantization of Conv2d and ConvTranspose2d (since SubMConv3d and SparseConv3d don’t have pre-defined quantization class right now, but we can always customize layers afterwards).\n4. Memory usage of each layer I tried self-written hooks to figure out the GPU memory usage of each layer, but it always seems that there’s some problem with my code. So I instead use profiler:\nAs we can see from the right side, the layer which has high GPU memory usage is the Sparse-Conv3d from the module spconv (Name: cumm:conv:....). But I can’t quite understand that why Conv2d didn’t use any of the GPU memory while has GPU time on them (on the right side).\n5. Storage usage of each layer (fvcore) | name | #elements or shape | |:----------------------------|:---------------------| | model | 8.9M | | backbone_3d | 2.7M | | backbone_3d.conv_input | 2.2K | | backbone_3d.conv_input.0 | 2.2K | | backbone_3d.conv_input.1 | 32 | | backbone_3d.conv1 | 27.8K | | backbone_3d.conv1.0 | 13.9K | | backbone_3d.conv1.1 | 13.9K | | backbone_3d.conv2 | 0.1M | | backbone_3d.conv2.0 | 13.9K | | backbone_3d.conv2.1 | 55.5K | | backbone_3d.conv2.2 | 55.5K | | backbone_3d.conv3 | 0.5M | | backbone_3d.conv3.0 | 55.4K | | backbone_3d.conv3.1 | 0.2M | | backbone_3d.conv3.2 | 0.2M | | backbone_3d.conv4 | 2.0M | | backbone_3d.conv4.0 | 0.2M | | backbone_3d.conv4.1 | 0.9M | | backbone_3d.conv4.2 | 0.9M | | backbone_3d.conv_out | 49.4K | | backbone_3d.conv_out.0 | 49.2K | | backbone_3d.conv_out.1 | 0.3K | | backbone_2d | 4.6M | | backbone_2d.blocks | 4.3M | | backbone_2d.blocks.0 | 1.0M | | backbone_2d.blocks.1 | 3.2M | | backbone_2d.deblocks | 0.3M | | backbone_2d.deblocks.0 | 33.3K | | backbone_2d.deblocks.1 | 0.3M | | dense_head | 1.7M | | dense_head.shared_conv | 0.3M | | dense_head.shared_conv.0 | 0.3M | | dense_head.shared_conv.1 | 0.1K | | dense_head.heads_list | 1.4M | | dense_head.heads_list.0 | 0.2M | | dense_head.heads_list.1 | 0.2M | | dense_head.heads_list.2 | 0.2M | | dense_head.heads_list.3 | 0.2M | | dense_head.heads_list.4 | 0.2M | | dense_head.heads_list.5 | 0.2M | And below is a storage diagram of a ResNet-50:\nSkipped operation aten::batch_norm 53 time(s) Skipped operation aten::max_pool2d 1 time(s) Skipped operation aten::add_ 16 time(s) Skipped operation aten::adaptive_avg_pool2d 1 time(s) FLOPs: 4089184256 | name | #elements or shape | |:-----------------------|:---------------------| | model | 25.6M | | conv1 | 9.4K | | conv1.weight | (64, 3, 7, 7) | | bn1 | 0.1K | | bn1.weight | (64,) | | bn1.bias | (64,) | | layer1 | 0.2M | | layer1.0 | 75.0K | | layer1.0.conv1 | 4.1K | | layer1.0.bn1 | 0.1K | | layer1.0.conv2 | 36.9K | | layer1.0.bn2 | 0.1K | | layer1.0.conv3 | 16.4K | | layer1.0.bn3 | 0.5K | | layer1.0.downsample | 16.9K | | layer1.1 | 70.4K | | layer1.1.conv1 | 16.4K | | layer1.1.bn1 | 0.1K | | layer1.1.conv2 | 36.9K | | layer1.1.bn2 | 0.1K | | layer1.1.conv3 | 16.4K | | layer1.1.bn3 | 0.5K | | layer1.2 | 70.4K | | layer1.2.conv1 | 16.4K | | layer1.2.bn1 | 0.1K | | layer1.2.conv2 | 36.9K | | layer1.2.bn2 | 0.1K | | layer1.2.conv3 | 16.4K | | layer1.2.bn3 | 0.5K | | layer2 | 1.2M | | layer2.0 | 0.4M | | layer2.0.conv1 | 32.8K | | layer2.0.bn1 | 0.3K | | layer2.0.conv2 | 0.1M | | layer2.0.bn2 | 0.3K | | layer2.0.conv3 | 65.5K | | layer2.0.bn3 | 1.0K | | layer2.0.downsample | 0.1M | | layer2.1 | 0.3M | | layer2.1.conv1 | 65.5K | | layer2.1.bn1 | 0.3K | | layer2.1.conv2 | 0.1M | | layer2.1.bn2 | 0.3K | | layer2.1.conv3 | 65.5K | | layer2.1.bn3 | 1.0K | | layer2.2 | 0.3M | | layer2.2.conv1 | 65.5K | | layer2.2.bn1 | 0.3K | | layer2.2.conv2 | 0.1M | | layer2.2.bn2 | 0.3K | | layer2.2.conv3 | 65.5K | | layer2.2.bn3 | 1.0K | | layer2.3 | 0.3M | | layer2.3.conv1 | 65.5K | | layer2.3.bn1 | 0.3K | | layer2.3.conv2 | 0.1M | | layer2.3.bn2 | 0.3K | | layer2.3.conv3 | 65.5K | | layer2.3.bn3 | 1.0K | | layer3 | 7.1M | | layer3.0 | 1.5M | | layer3.0.conv1 | 0.1M | | layer3.0.bn1 | 0.5K | | layer3.0.conv2 | 0.6M | | layer3.0.bn2 | 0.5K | | layer3.0.conv3 | 0.3M | | layer3.0.bn3 | 2.0K | | layer3.0.downsample | 0.5M | | layer3.1 | 1.1M | | layer3.1.conv1 | 0.3M | | layer3.1.bn1 | 0.5K | | layer3.1.conv2 | 0.6M | | layer3.1.bn2 | 0.5K | | layer3.1.conv3 | 0.3M | | layer3.1.bn3 | 2.0K | | layer3.2 | 1.1M | | layer3.2.conv1 | 0.3M | | layer3.2.bn1 | 0.5K | | layer3.2.conv2 | 0.6M | | layer3.2.bn2 | 0.5K | | layer3.2.conv3 | 0.3M | | layer3.2.bn3 | 2.0K | | layer3.3 | 1.1M | | layer3.3.conv1 | 0.3M | | layer3.3.bn1 | 0.5K | | layer3.3.conv2 | 0.6M | | layer3.3.bn2 | 0.5K | | layer3.3.conv3 | 0.3M | | layer3.3.bn3 | 2.0K | | layer3.4 | 1.1M | | layer3.4.conv1 | 0.3M | | layer3.4.bn1 | 0.5K | | layer3.4.conv2 | 0.6M | | layer3.4.bn2 | 0.5K | | layer3.4.conv3 | 0.3M | | layer3.4.bn3 | 2.0K | | layer3.5 | 1.1M | | layer3.5.conv1 | 0.3M | | layer3.5.bn1 | 0.5K | | layer3.5.conv2 | 0.6M | | layer3.5.bn2 | 0.5K | | layer3.5.conv3 | 0.3M | | layer3.5.bn3 | 2.0K | | layer4 | 15.0M | | layer4.0 | 6.0M | | layer4.0.conv1 | 0.5M | | layer4.0.bn1 | 1.0K | | layer4.0.conv2 | 2.4M | | layer4.0.bn2 | 1.0K | | layer4.0.conv3 | 1.0M | | layer4.0.bn3 | 4.1K | | layer4.0.downsample | 2.1M | | layer4.1 | 4.5M | | layer4.1.conv1 | 1.0M | | layer4.1.bn1 | 1.0K | | layer4.1.conv2 | 2.4M | | layer4.1.bn2 | 1.0K | | layer4.1.conv3 | 1.0M | | layer4.1.bn3 | 4.1K | | layer4.2 | 4.5M | | layer4.2.conv1 | 1.0M | | layer4.2.bn1 | 1.0K | | layer4.2.conv2 | 2.4M | | layer4.2.bn2 | 1.0K | | layer4.2.conv3 | 1.0M | | layer4.2.bn3 | 4.1K | | fc | 2.0M | | fc.weight | (1000, 2048) | | fc.bias | (1000,) | The reason why I also attached a table of ResNet-50 model is that I want to point out the fact that the storage usage of CenterPoint is less than that of ResNet-50.\nFrom my perspective, it (may) be common that LiDAR-based 3D object detection model’s storage usage is smaller than traditional 2D model, since LiDAR-based 3D object detection model’s 3D backbone are using spconv module, a module that take the sparsity nature of Conv3d into consideration and therefore reduce the model storage usage, GPU memory usage and inference time. So it makes sense that from a perspective of storage usage, 3D \u003c 2D.\nBack to our original topic, from the first table, we can clearly see that backbone_2d is the most storage-consuming layer, which means we can start from quantization of Conv2d initially.\n6. Quantization of the model Here we try both dynamic and static PTQ only on Conv2d, i.e., have some calibration data flowed within the model, so that the quantizer can get a good idea of the dynamic range of the activation.\nOriginal results: dynamic calibration-max quantization results: with model layer’s amax is dynamic:\nstatic calibration-max quantization results: with model layer’s amax is a specific range or number:\nWeight-only quantization: with model input quantizer’s num_bits is 16-bit:\n7. Conclusion We can clearly see that the results are only effected a little bit on the basis that we only quantized 2D conv (But this can be due to the optimization of pytorch-quantization). So I think our potential next target will be the spconv layer. Based on the documentation of the pytorch-quantization, we can customize our own quantized layer just like below: ",
  "wordCount" : "3277",
  "inLanguage": "en",
  "datePublished": "2024-04-26T15:32:56-05:00",
  "dateModified": "2024-04-26T15:32:56-05:00",
  "author":{
    "@type": "Person",
    "name": "Banghao Chi"
  },
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://banghao.live/blog/4/"
  },
  "publisher": {
    "@type": "Organization",
    "name": "Banghao's Blog",
    "logo": {
      "@type": "ImageObject",
      "url": "https://banghao.live/favicon.ico"
    }
  }
}
</script>
</head>

<body class="" id="top">
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    } else if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark')
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.body.classList.add('dark');
    }

</script>

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="https://banghao.live/" accesskey="h" title="Banghao&#39;s Blog (Alt + H)">Banghao&#39;s Blog</a>
            <div class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
            </div>
        </div>
        <ul id="menu">
            <li>
                <a href="https://banghao.live/categories/" title="Categories">
                    <span>Categories</span>
                </a>
            </li>
            <li>
                <a href="https://banghao.live/tags/" title="Tags">
                    <span>Tags</span>
                </a>
            </li>
            <li>
                <a href="https://banghao.live/archives/" title="Archives">
                    <span>Archives</span>
                </a>
            </li>
            <li>
                <a href="https://banghao.studio/login" title="Forum App">
                    <span>Forum App</span>&nbsp;
                    <svg fill="none" shape-rendering="geometricPrecision" stroke="currentColor" stroke-linecap="round"
                        stroke-linejoin="round" stroke-width="2.5" viewBox="0 0 24 24" height="12" width="12">
                        <path d="M18 13v6a2 2 0 01-2 2H5a2 2 0 01-2-2V8a2 2 0 012-2h6"></path>
                        <path d="M15 3h6v6"></path>
                        <path d="M10 14L21 3"></path>
                    </svg>
                </a>
            </li>
        </ul>
    </nav>
</header>
<main class="main">

<article class="post-single">
  <header class="post-header">
    
    <h1 class="post-title entry-hint-parent">
      Meeting Discussion (4)
    </h1>
    <div class="post-meta"><span title='2024-04-26 15:32:56 -0500 -0500'>April 26, 2024</span>&nbsp;·&nbsp;16 min&nbsp;·&nbsp;Banghao Chi

</div>
  </header> 
  <div class="post-content"><h4 id="1-table-of-contents">1. Table of Contents<a hidden class="anchor" aria-hidden="true" href="#1-table-of-contents">#</a></h4>
<ul>
<li>The strcuture of the CenterPoint-Vexel model: ✅</li>
<li>Inference time of each layer: ✅</li>
<li>Memory usage of each layer: ✅</li>
<li>Storage usage of each layer: ✅</li>
<li>Quantization of the model: ✅</li>
</ul>
<h4 id="2-the-strcuture-of-the-centerpoint-vexel-model">2. The strcuture of the CenterPoint-Vexel model<a hidden class="anchor" aria-hidden="true" href="#2-the-strcuture-of-the-centerpoint-vexel-model">#</a></h4>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>CenterPoint(
</span></span><span style="display:flex;"><span>  (vfe): MeanVFE()
</span></span><span style="display:flex;"><span>  (backbone_3d): VoxelResBackBone8x(
</span></span><span style="display:flex;"><span>    (conv_input): SparseSequential(
</span></span><span style="display:flex;"><span>      (<span style="color:#ae81ff">0</span>): SubMConv3d(<span style="color:#ae81ff">5</span>, <span style="color:#ae81ff">16</span>, kernel_size<span style="color:#f92672">=</span>[<span style="color:#ae81ff">3</span>, <span style="color:#ae81ff">3</span>, <span style="color:#ae81ff">3</span>], stride<span style="color:#f92672">=</span>[<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>], padding<span style="color:#f92672">=</span>[<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>], dilation<span style="color:#f92672">=</span>[<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>], output_padding<span style="color:#f92672">=</span>[<span style="color:#ae81ff">0</span>, <span style="color:#ae81ff">0</span>, <span style="color:#ae81ff">0</span>], bias<span style="color:#f92672">=</span><span style="color:#66d9ef">False</span>, algo<span style="color:#f92672">=</span>ConvAlgo<span style="color:#f92672">.</span>MaskImplicitGemm)
</span></span><span style="display:flex;"><span>      (<span style="color:#ae81ff">1</span>): BatchNorm1d(<span style="color:#ae81ff">16</span>, eps<span style="color:#f92672">=</span><span style="color:#ae81ff">0.001</span>, momentum<span style="color:#f92672">=</span><span style="color:#ae81ff">0.01</span>, affine<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>, track_running_stats<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>)
</span></span><span style="display:flex;"><span>      (<span style="color:#ae81ff">2</span>): ReLU()
</span></span><span style="display:flex;"><span>    )
</span></span><span style="display:flex;"><span>    (conv1): SparseSequential(
</span></span><span style="display:flex;"><span>      (<span style="color:#ae81ff">0</span>): SparseBasicBlock(
</span></span><span style="display:flex;"><span>        (conv1): SubMConv3d(<span style="color:#ae81ff">16</span>, <span style="color:#ae81ff">16</span>, kernel_size<span style="color:#f92672">=</span>[<span style="color:#ae81ff">3</span>, <span style="color:#ae81ff">3</span>, <span style="color:#ae81ff">3</span>], stride<span style="color:#f92672">=</span>[<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>], padding<span style="color:#f92672">=</span>[<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>], dilation<span style="color:#f92672">=</span>[<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>], output_padding<span style="color:#f92672">=</span>[<span style="color:#ae81ff">0</span>, <span style="color:#ae81ff">0</span>, <span style="color:#ae81ff">0</span>], algo<span style="color:#f92672">=</span>ConvAlgo<span style="color:#f92672">.</span>MaskImplicitGemm)
</span></span><span style="display:flex;"><span>        (bn1): BatchNorm1d(<span style="color:#ae81ff">16</span>, eps<span style="color:#f92672">=</span><span style="color:#ae81ff">0.001</span>, momentum<span style="color:#f92672">=</span><span style="color:#ae81ff">0.01</span>, affine<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>, track_running_stats<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>)
</span></span><span style="display:flex;"><span>        (relu): ReLU()
</span></span><span style="display:flex;"><span>        (conv2): SubMConv3d(<span style="color:#ae81ff">16</span>, <span style="color:#ae81ff">16</span>, kernel_size<span style="color:#f92672">=</span>[<span style="color:#ae81ff">3</span>, <span style="color:#ae81ff">3</span>, <span style="color:#ae81ff">3</span>], stride<span style="color:#f92672">=</span>[<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>], padding<span style="color:#f92672">=</span>[<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>], dilation<span style="color:#f92672">=</span>[<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>], output_padding<span style="color:#f92672">=</span>[<span style="color:#ae81ff">0</span>, <span style="color:#ae81ff">0</span>, <span style="color:#ae81ff">0</span>], algo<span style="color:#f92672">=</span>ConvAlgo<span style="color:#f92672">.</span>MaskImplicitGemm)
</span></span><span style="display:flex;"><span>        (bn2): BatchNorm1d(<span style="color:#ae81ff">16</span>, eps<span style="color:#f92672">=</span><span style="color:#ae81ff">0.001</span>, momentum<span style="color:#f92672">=</span><span style="color:#ae81ff">0.01</span>, affine<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>, track_running_stats<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>)
</span></span><span style="display:flex;"><span>      )
</span></span><span style="display:flex;"><span>      (<span style="color:#ae81ff">1</span>): SparseBasicBlock(
</span></span><span style="display:flex;"><span>        (conv1): SubMConv3d(<span style="color:#ae81ff">16</span>, <span style="color:#ae81ff">16</span>, kernel_size<span style="color:#f92672">=</span>[<span style="color:#ae81ff">3</span>, <span style="color:#ae81ff">3</span>, <span style="color:#ae81ff">3</span>], stride<span style="color:#f92672">=</span>[<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>], padding<span style="color:#f92672">=</span>[<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>], dilation<span style="color:#f92672">=</span>[<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>], output_padding<span style="color:#f92672">=</span>[<span style="color:#ae81ff">0</span>, <span style="color:#ae81ff">0</span>, <span style="color:#ae81ff">0</span>], algo<span style="color:#f92672">=</span>ConvAlgo<span style="color:#f92672">.</span>MaskImplicitGemm)
</span></span><span style="display:flex;"><span>        (bn1): BatchNorm1d(<span style="color:#ae81ff">16</span>, eps<span style="color:#f92672">=</span><span style="color:#ae81ff">0.001</span>, momentum<span style="color:#f92672">=</span><span style="color:#ae81ff">0.01</span>, affine<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>, track_running_stats<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>)
</span></span><span style="display:flex;"><span>        (relu): ReLU()
</span></span><span style="display:flex;"><span>        (conv2): SubMConv3d(<span style="color:#ae81ff">16</span>, <span style="color:#ae81ff">16</span>, kernel_size<span style="color:#f92672">=</span>[<span style="color:#ae81ff">3</span>, <span style="color:#ae81ff">3</span>, <span style="color:#ae81ff">3</span>], stride<span style="color:#f92672">=</span>[<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>], padding<span style="color:#f92672">=</span>[<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>], dilation<span style="color:#f92672">=</span>[<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>], output_padding<span style="color:#f92672">=</span>[<span style="color:#ae81ff">0</span>, <span style="color:#ae81ff">0</span>, <span style="color:#ae81ff">0</span>], algo<span style="color:#f92672">=</span>ConvAlgo<span style="color:#f92672">.</span>MaskImplicitGemm)
</span></span><span style="display:flex;"><span>        (bn2): BatchNorm1d(<span style="color:#ae81ff">16</span>, eps<span style="color:#f92672">=</span><span style="color:#ae81ff">0.001</span>, momentum<span style="color:#f92672">=</span><span style="color:#ae81ff">0.01</span>, affine<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>, track_running_stats<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>)
</span></span><span style="display:flex;"><span>      )
</span></span><span style="display:flex;"><span>    )
</span></span><span style="display:flex;"><span>    (conv2): SparseSequential(
</span></span><span style="display:flex;"><span>      (<span style="color:#ae81ff">0</span>): SparseSequential(
</span></span><span style="display:flex;"><span>        (<span style="color:#ae81ff">0</span>): SparseConv3d(<span style="color:#ae81ff">16</span>, <span style="color:#ae81ff">32</span>, kernel_size<span style="color:#f92672">=</span>[<span style="color:#ae81ff">3</span>, <span style="color:#ae81ff">3</span>, <span style="color:#ae81ff">3</span>], stride<span style="color:#f92672">=</span>[<span style="color:#ae81ff">2</span>, <span style="color:#ae81ff">2</span>, <span style="color:#ae81ff">2</span>], padding<span style="color:#f92672">=</span>[<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>], dilation<span style="color:#f92672">=</span>[<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>], output_padding<span style="color:#f92672">=</span>[<span style="color:#ae81ff">0</span>, <span style="color:#ae81ff">0</span>, <span style="color:#ae81ff">0</span>], bias<span style="color:#f92672">=</span><span style="color:#66d9ef">False</span>, algo<span style="color:#f92672">=</span>ConvAlgo<span style="color:#f92672">.</span>MaskImplicitGemm)
</span></span><span style="display:flex;"><span>        (<span style="color:#ae81ff">1</span>): BatchNorm1d(<span style="color:#ae81ff">32</span>, eps<span style="color:#f92672">=</span><span style="color:#ae81ff">0.001</span>, momentum<span style="color:#f92672">=</span><span style="color:#ae81ff">0.01</span>, affine<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>, track_running_stats<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>)
</span></span><span style="display:flex;"><span>        (<span style="color:#ae81ff">2</span>): ReLU()
</span></span><span style="display:flex;"><span>      )
</span></span><span style="display:flex;"><span>      (<span style="color:#ae81ff">1</span>): SparseBasicBlock(
</span></span><span style="display:flex;"><span>        (conv1): SubMConv3d(<span style="color:#ae81ff">32</span>, <span style="color:#ae81ff">32</span>, kernel_size<span style="color:#f92672">=</span>[<span style="color:#ae81ff">3</span>, <span style="color:#ae81ff">3</span>, <span style="color:#ae81ff">3</span>], stride<span style="color:#f92672">=</span>[<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>], padding<span style="color:#f92672">=</span>[<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>], dilation<span style="color:#f92672">=</span>[<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>], output_padding<span style="color:#f92672">=</span>[<span style="color:#ae81ff">0</span>, <span style="color:#ae81ff">0</span>, <span style="color:#ae81ff">0</span>], algo<span style="color:#f92672">=</span>ConvAlgo<span style="color:#f92672">.</span>MaskImplicitGemm)
</span></span><span style="display:flex;"><span>        (bn1): BatchNorm1d(<span style="color:#ae81ff">32</span>, eps<span style="color:#f92672">=</span><span style="color:#ae81ff">0.001</span>, momentum<span style="color:#f92672">=</span><span style="color:#ae81ff">0.01</span>, affine<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>, track_running_stats<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>)
</span></span><span style="display:flex;"><span>        (relu): ReLU()
</span></span><span style="display:flex;"><span>        (conv2): SubMConv3d(<span style="color:#ae81ff">32</span>, <span style="color:#ae81ff">32</span>, kernel_size<span style="color:#f92672">=</span>[<span style="color:#ae81ff">3</span>, <span style="color:#ae81ff">3</span>, <span style="color:#ae81ff">3</span>], stride<span style="color:#f92672">=</span>[<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>], padding<span style="color:#f92672">=</span>[<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>], dilation<span style="color:#f92672">=</span>[<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>], output_padding<span style="color:#f92672">=</span>[<span style="color:#ae81ff">0</span>, <span style="color:#ae81ff">0</span>, <span style="color:#ae81ff">0</span>], algo<span style="color:#f92672">=</span>ConvAlgo<span style="color:#f92672">.</span>MaskImplicitGemm)
</span></span><span style="display:flex;"><span>        (bn2): BatchNorm1d(<span style="color:#ae81ff">32</span>, eps<span style="color:#f92672">=</span><span style="color:#ae81ff">0.001</span>, momentum<span style="color:#f92672">=</span><span style="color:#ae81ff">0.01</span>, affine<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>, track_running_stats<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>)
</span></span><span style="display:flex;"><span>      )
</span></span><span style="display:flex;"><span>      (<span style="color:#ae81ff">2</span>): SparseBasicBlock(
</span></span><span style="display:flex;"><span>        (conv1): SubMConv3d(<span style="color:#ae81ff">32</span>, <span style="color:#ae81ff">32</span>, kernel_size<span style="color:#f92672">=</span>[<span style="color:#ae81ff">3</span>, <span style="color:#ae81ff">3</span>, <span style="color:#ae81ff">3</span>], stride<span style="color:#f92672">=</span>[<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>], padding<span style="color:#f92672">=</span>[<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>], dilation<span style="color:#f92672">=</span>[<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>], output_padding<span style="color:#f92672">=</span>[<span style="color:#ae81ff">0</span>, <span style="color:#ae81ff">0</span>, <span style="color:#ae81ff">0</span>], algo<span style="color:#f92672">=</span>ConvAlgo<span style="color:#f92672">.</span>MaskImplicitGemm)
</span></span><span style="display:flex;"><span>        (bn1): BatchNorm1d(<span style="color:#ae81ff">32</span>, eps<span style="color:#f92672">=</span><span style="color:#ae81ff">0.001</span>, momentum<span style="color:#f92672">=</span><span style="color:#ae81ff">0.01</span>, affine<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>, track_running_stats<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>)
</span></span><span style="display:flex;"><span>        (relu): ReLU()
</span></span><span style="display:flex;"><span>        (conv2): SubMConv3d(<span style="color:#ae81ff">32</span>, <span style="color:#ae81ff">32</span>, kernel_size<span style="color:#f92672">=</span>[<span style="color:#ae81ff">3</span>, <span style="color:#ae81ff">3</span>, <span style="color:#ae81ff">3</span>], stride<span style="color:#f92672">=</span>[<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>], padding<span style="color:#f92672">=</span>[<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>], dilation<span style="color:#f92672">=</span>[<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>], output_padding<span style="color:#f92672">=</span>[<span style="color:#ae81ff">0</span>, <span style="color:#ae81ff">0</span>, <span style="color:#ae81ff">0</span>], algo<span style="color:#f92672">=</span>ConvAlgo<span style="color:#f92672">.</span>MaskImplicitGemm)
</span></span><span style="display:flex;"><span>        (bn2): BatchNorm1d(<span style="color:#ae81ff">32</span>, eps<span style="color:#f92672">=</span><span style="color:#ae81ff">0.001</span>, momentum<span style="color:#f92672">=</span><span style="color:#ae81ff">0.01</span>, affine<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>, track_running_stats<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>)
</span></span><span style="display:flex;"><span>      )
</span></span><span style="display:flex;"><span>    )
</span></span><span style="display:flex;"><span>    (conv3): SparseSequential(
</span></span><span style="display:flex;"><span>      (<span style="color:#ae81ff">0</span>): SparseSequential(
</span></span><span style="display:flex;"><span>        (<span style="color:#ae81ff">0</span>): SparseConv3d(<span style="color:#ae81ff">32</span>, <span style="color:#ae81ff">64</span>, kernel_size<span style="color:#f92672">=</span>[<span style="color:#ae81ff">3</span>, <span style="color:#ae81ff">3</span>, <span style="color:#ae81ff">3</span>], stride<span style="color:#f92672">=</span>[<span style="color:#ae81ff">2</span>, <span style="color:#ae81ff">2</span>, <span style="color:#ae81ff">2</span>], padding<span style="color:#f92672">=</span>[<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>], dilation<span style="color:#f92672">=</span>[<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>], output_padding<span style="color:#f92672">=</span>[<span style="color:#ae81ff">0</span>, <span style="color:#ae81ff">0</span>, <span style="color:#ae81ff">0</span>], bias<span style="color:#f92672">=</span><span style="color:#66d9ef">False</span>, algo<span style="color:#f92672">=</span>ConvAlgo<span style="color:#f92672">.</span>MaskImplicitGemm)
</span></span><span style="display:flex;"><span>        (<span style="color:#ae81ff">1</span>): BatchNorm1d(<span style="color:#ae81ff">64</span>, eps<span style="color:#f92672">=</span><span style="color:#ae81ff">0.001</span>, momentum<span style="color:#f92672">=</span><span style="color:#ae81ff">0.01</span>, affine<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>, track_running_stats<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>)
</span></span><span style="display:flex;"><span>        (<span style="color:#ae81ff">2</span>): ReLU()
</span></span><span style="display:flex;"><span>      )
</span></span><span style="display:flex;"><span>      (<span style="color:#ae81ff">1</span>): SparseBasicBlock(
</span></span><span style="display:flex;"><span>        (conv1): SubMConv3d(<span style="color:#ae81ff">64</span>, <span style="color:#ae81ff">64</span>, kernel_size<span style="color:#f92672">=</span>[<span style="color:#ae81ff">3</span>, <span style="color:#ae81ff">3</span>, <span style="color:#ae81ff">3</span>], stride<span style="color:#f92672">=</span>[<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>], padding<span style="color:#f92672">=</span>[<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>], dilation<span style="color:#f92672">=</span>[<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>], output_padding<span style="color:#f92672">=</span>[<span style="color:#ae81ff">0</span>, <span style="color:#ae81ff">0</span>, <span style="color:#ae81ff">0</span>], algo<span style="color:#f92672">=</span>ConvAlgo<span style="color:#f92672">.</span>MaskImplicitGemm)
</span></span><span style="display:flex;"><span>        (bn1): BatchNorm1d(<span style="color:#ae81ff">64</span>, eps<span style="color:#f92672">=</span><span style="color:#ae81ff">0.001</span>, momentum<span style="color:#f92672">=</span><span style="color:#ae81ff">0.01</span>, affine<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>, track_running_stats<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>)
</span></span><span style="display:flex;"><span>        (relu): ReLU()
</span></span><span style="display:flex;"><span>        (conv2): SubMConv3d(<span style="color:#ae81ff">64</span>, <span style="color:#ae81ff">64</span>, kernel_size<span style="color:#f92672">=</span>[<span style="color:#ae81ff">3</span>, <span style="color:#ae81ff">3</span>, <span style="color:#ae81ff">3</span>], stride<span style="color:#f92672">=</span>[<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>], padding<span style="color:#f92672">=</span>[<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>], dilation<span style="color:#f92672">=</span>[<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>], output_padding<span style="color:#f92672">=</span>[<span style="color:#ae81ff">0</span>, <span style="color:#ae81ff">0</span>, <span style="color:#ae81ff">0</span>], algo<span style="color:#f92672">=</span>ConvAlgo<span style="color:#f92672">.</span>MaskImplicitGemm)
</span></span><span style="display:flex;"><span>        (bn2): BatchNorm1d(<span style="color:#ae81ff">64</span>, eps<span style="color:#f92672">=</span><span style="color:#ae81ff">0.001</span>, momentum<span style="color:#f92672">=</span><span style="color:#ae81ff">0.01</span>, affine<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>, track_running_stats<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>)
</span></span><span style="display:flex;"><span>      )
</span></span><span style="display:flex;"><span>      (<span style="color:#ae81ff">2</span>): SparseBasicBlock(
</span></span><span style="display:flex;"><span>        (conv1): SubMConv3d(<span style="color:#ae81ff">64</span>, <span style="color:#ae81ff">64</span>, kernel_size<span style="color:#f92672">=</span>[<span style="color:#ae81ff">3</span>, <span style="color:#ae81ff">3</span>, <span style="color:#ae81ff">3</span>], stride<span style="color:#f92672">=</span>[<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>], padding<span style="color:#f92672">=</span>[<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>], dilation<span style="color:#f92672">=</span>[<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>], output_padding<span style="color:#f92672">=</span>[<span style="color:#ae81ff">0</span>, <span style="color:#ae81ff">0</span>, <span style="color:#ae81ff">0</span>], algo<span style="color:#f92672">=</span>ConvAlgo<span style="color:#f92672">.</span>MaskImplicitGemm)
</span></span><span style="display:flex;"><span>        (bn1): BatchNorm1d(<span style="color:#ae81ff">64</span>, eps<span style="color:#f92672">=</span><span style="color:#ae81ff">0.001</span>, momentum<span style="color:#f92672">=</span><span style="color:#ae81ff">0.01</span>, affine<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>, track_running_stats<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>)
</span></span><span style="display:flex;"><span>        (relu): ReLU()
</span></span><span style="display:flex;"><span>        (conv2): SubMConv3d(<span style="color:#ae81ff">64</span>, <span style="color:#ae81ff">64</span>, kernel_size<span style="color:#f92672">=</span>[<span style="color:#ae81ff">3</span>, <span style="color:#ae81ff">3</span>, <span style="color:#ae81ff">3</span>], stride<span style="color:#f92672">=</span>[<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>], padding<span style="color:#f92672">=</span>[<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>], dilation<span style="color:#f92672">=</span>[<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>], output_padding<span style="color:#f92672">=</span>[<span style="color:#ae81ff">0</span>, <span style="color:#ae81ff">0</span>, <span style="color:#ae81ff">0</span>], algo<span style="color:#f92672">=</span>ConvAlgo<span style="color:#f92672">.</span>MaskImplicitGemm)
</span></span><span style="display:flex;"><span>        (bn2): BatchNorm1d(<span style="color:#ae81ff">64</span>, eps<span style="color:#f92672">=</span><span style="color:#ae81ff">0.001</span>, momentum<span style="color:#f92672">=</span><span style="color:#ae81ff">0.01</span>, affine<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>, track_running_stats<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>)
</span></span><span style="display:flex;"><span>      )
</span></span><span style="display:flex;"><span>    )
</span></span><span style="display:flex;"><span>    (conv4): SparseSequential(
</span></span><span style="display:flex;"><span>      (<span style="color:#ae81ff">0</span>): SparseSequential(
</span></span><span style="display:flex;"><span>        (<span style="color:#ae81ff">0</span>): SparseConv3d(<span style="color:#ae81ff">64</span>, <span style="color:#ae81ff">128</span>, kernel_size<span style="color:#f92672">=</span>[<span style="color:#ae81ff">3</span>, <span style="color:#ae81ff">3</span>, <span style="color:#ae81ff">3</span>], stride<span style="color:#f92672">=</span>[<span style="color:#ae81ff">2</span>, <span style="color:#ae81ff">2</span>, <span style="color:#ae81ff">2</span>], padding<span style="color:#f92672">=</span>[<span style="color:#ae81ff">0</span>, <span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>], dilation<span style="color:#f92672">=</span>[<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>], output_padding<span style="color:#f92672">=</span>[<span style="color:#ae81ff">0</span>, <span style="color:#ae81ff">0</span>, <span style="color:#ae81ff">0</span>], bias<span style="color:#f92672">=</span><span style="color:#66d9ef">False</span>, algo<span style="color:#f92672">=</span>ConvAlgo<span style="color:#f92672">.</span>MaskImplicitGemm)
</span></span><span style="display:flex;"><span>        (<span style="color:#ae81ff">1</span>): BatchNorm1d(<span style="color:#ae81ff">128</span>, eps<span style="color:#f92672">=</span><span style="color:#ae81ff">0.001</span>, momentum<span style="color:#f92672">=</span><span style="color:#ae81ff">0.01</span>, affine<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>, track_running_stats<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>)
</span></span><span style="display:flex;"><span>        (<span style="color:#ae81ff">2</span>): ReLU()
</span></span><span style="display:flex;"><span>      )
</span></span><span style="display:flex;"><span>      (<span style="color:#ae81ff">1</span>): SparseBasicBlock(
</span></span><span style="display:flex;"><span>        (conv1): SubMConv3d(<span style="color:#ae81ff">128</span>, <span style="color:#ae81ff">128</span>, kernel_size<span style="color:#f92672">=</span>[<span style="color:#ae81ff">3</span>, <span style="color:#ae81ff">3</span>, <span style="color:#ae81ff">3</span>], stride<span style="color:#f92672">=</span>[<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>], padding<span style="color:#f92672">=</span>[<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>], dilation<span style="color:#f92672">=</span>[<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>], output_padding<span style="color:#f92672">=</span>[<span style="color:#ae81ff">0</span>, <span style="color:#ae81ff">0</span>, <span style="color:#ae81ff">0</span>], algo<span style="color:#f92672">=</span>ConvAlgo<span style="color:#f92672">.</span>MaskImplicitGemm)
</span></span><span style="display:flex;"><span>        (bn1): BatchNorm1d(<span style="color:#ae81ff">128</span>, eps<span style="color:#f92672">=</span><span style="color:#ae81ff">0.001</span>, momentum<span style="color:#f92672">=</span><span style="color:#ae81ff">0.01</span>, affine<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>, track_running_stats<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>)
</span></span><span style="display:flex;"><span>        (relu): ReLU()
</span></span><span style="display:flex;"><span>        (conv2): SubMConv3d(<span style="color:#ae81ff">128</span>, <span style="color:#ae81ff">128</span>, kernel_size<span style="color:#f92672">=</span>[<span style="color:#ae81ff">3</span>, <span style="color:#ae81ff">3</span>, <span style="color:#ae81ff">3</span>], stride<span style="color:#f92672">=</span>[<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>], padding<span style="color:#f92672">=</span>[<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>], dilation<span style="color:#f92672">=</span>[<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>], output_padding<span style="color:#f92672">=</span>[<span style="color:#ae81ff">0</span>, <span style="color:#ae81ff">0</span>, <span style="color:#ae81ff">0</span>], algo<span style="color:#f92672">=</span>ConvAlgo<span style="color:#f92672">.</span>MaskImplicitGemm)
</span></span><span style="display:flex;"><span>        (bn2): BatchNorm1d(<span style="color:#ae81ff">128</span>, eps<span style="color:#f92672">=</span><span style="color:#ae81ff">0.001</span>, momentum<span style="color:#f92672">=</span><span style="color:#ae81ff">0.01</span>, affine<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>, track_running_stats<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>)
</span></span><span style="display:flex;"><span>      )
</span></span><span style="display:flex;"><span>      (<span style="color:#ae81ff">2</span>): SparseBasicBlock(
</span></span><span style="display:flex;"><span>        (conv1): SubMConv3d(<span style="color:#ae81ff">128</span>, <span style="color:#ae81ff">128</span>, kernel_size<span style="color:#f92672">=</span>[<span style="color:#ae81ff">3</span>, <span style="color:#ae81ff">3</span>, <span style="color:#ae81ff">3</span>], stride<span style="color:#f92672">=</span>[<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>], padding<span style="color:#f92672">=</span>[<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>], dilation<span style="color:#f92672">=</span>[<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>], output_padding<span style="color:#f92672">=</span>[<span style="color:#ae81ff">0</span>, <span style="color:#ae81ff">0</span>, <span style="color:#ae81ff">0</span>], algo<span style="color:#f92672">=</span>ConvAlgo<span style="color:#f92672">.</span>MaskImplicitGemm)
</span></span><span style="display:flex;"><span>        (bn1): BatchNorm1d(<span style="color:#ae81ff">128</span>, eps<span style="color:#f92672">=</span><span style="color:#ae81ff">0.001</span>, momentum<span style="color:#f92672">=</span><span style="color:#ae81ff">0.01</span>, affine<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>, track_running_stats<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>)
</span></span><span style="display:flex;"><span>        (relu): ReLU()
</span></span><span style="display:flex;"><span>        (conv2): SubMConv3d(<span style="color:#ae81ff">128</span>, <span style="color:#ae81ff">128</span>, kernel_size<span style="color:#f92672">=</span>[<span style="color:#ae81ff">3</span>, <span style="color:#ae81ff">3</span>, <span style="color:#ae81ff">3</span>], stride<span style="color:#f92672">=</span>[<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>], padding<span style="color:#f92672">=</span>[<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>], dilation<span style="color:#f92672">=</span>[<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>], output_padding<span style="color:#f92672">=</span>[<span style="color:#ae81ff">0</span>, <span style="color:#ae81ff">0</span>, <span style="color:#ae81ff">0</span>], algo<span style="color:#f92672">=</span>ConvAlgo<span style="color:#f92672">.</span>MaskImplicitGemm)
</span></span><span style="display:flex;"><span>        (bn2): BatchNorm1d(<span style="color:#ae81ff">128</span>, eps<span style="color:#f92672">=</span><span style="color:#ae81ff">0.001</span>, momentum<span style="color:#f92672">=</span><span style="color:#ae81ff">0.01</span>, affine<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>, track_running_stats<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>)
</span></span><span style="display:flex;"><span>      )
</span></span><span style="display:flex;"><span>    )
</span></span><span style="display:flex;"><span>    (conv_out): SparseSequential(
</span></span><span style="display:flex;"><span>      (<span style="color:#ae81ff">0</span>): SparseConv3d(<span style="color:#ae81ff">128</span>, <span style="color:#ae81ff">128</span>, kernel_size<span style="color:#f92672">=</span>[<span style="color:#ae81ff">3</span>, <span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>], stride<span style="color:#f92672">=</span>[<span style="color:#ae81ff">2</span>, <span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>], padding<span style="color:#f92672">=</span>[<span style="color:#ae81ff">0</span>, <span style="color:#ae81ff">0</span>, <span style="color:#ae81ff">0</span>], dilation<span style="color:#f92672">=</span>[<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>], output_padding<span style="color:#f92672">=</span>[<span style="color:#ae81ff">0</span>, <span style="color:#ae81ff">0</span>, <span style="color:#ae81ff">0</span>], bias<span style="color:#f92672">=</span><span style="color:#66d9ef">False</span>, algo<span style="color:#f92672">=</span>ConvAlgo<span style="color:#f92672">.</span>MaskImplicitGemm)
</span></span><span style="display:flex;"><span>      (<span style="color:#ae81ff">1</span>): BatchNorm1d(<span style="color:#ae81ff">128</span>, eps<span style="color:#f92672">=</span><span style="color:#ae81ff">0.001</span>, momentum<span style="color:#f92672">=</span><span style="color:#ae81ff">0.01</span>, affine<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>, track_running_stats<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>)
</span></span><span style="display:flex;"><span>      (<span style="color:#ae81ff">2</span>): ReLU()
</span></span><span style="display:flex;"><span>    )
</span></span><span style="display:flex;"><span>  )
</span></span><span style="display:flex;"><span>  (map_to_bev_module): HeightCompression()
</span></span><span style="display:flex;"><span>  (pfe): <span style="color:#66d9ef">None</span>
</span></span><span style="display:flex;"><span>  (backbone_2d): BaseBEVBackbone(
</span></span><span style="display:flex;"><span>    (blocks): ModuleList(
</span></span><span style="display:flex;"><span>      (<span style="color:#ae81ff">0</span>): Sequential(
</span></span><span style="display:flex;"><span>        (<span style="color:#ae81ff">0</span>): ZeroPad2d((<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>))
</span></span><span style="display:flex;"><span>        (<span style="color:#ae81ff">1</span>): Conv2d(<span style="color:#ae81ff">256</span>, <span style="color:#ae81ff">128</span>, kernel_size<span style="color:#f92672">=</span>(<span style="color:#ae81ff">3</span>, <span style="color:#ae81ff">3</span>), stride<span style="color:#f92672">=</span>(<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>), bias<span style="color:#f92672">=</span><span style="color:#66d9ef">False</span>)
</span></span><span style="display:flex;"><span>        (<span style="color:#ae81ff">2</span>): BatchNorm2d(<span style="color:#ae81ff">128</span>, eps<span style="color:#f92672">=</span><span style="color:#ae81ff">0.001</span>, momentum<span style="color:#f92672">=</span><span style="color:#ae81ff">0.01</span>, affine<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>, track_running_stats<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>)
</span></span><span style="display:flex;"><span>        (<span style="color:#ae81ff">3</span>): ReLU()
</span></span><span style="display:flex;"><span>        (<span style="color:#ae81ff">4</span>): Conv2d(<span style="color:#ae81ff">128</span>, <span style="color:#ae81ff">128</span>, kernel_size<span style="color:#f92672">=</span>(<span style="color:#ae81ff">3</span>, <span style="color:#ae81ff">3</span>), stride<span style="color:#f92672">=</span>(<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>), padding<span style="color:#f92672">=</span>(<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>), bias<span style="color:#f92672">=</span><span style="color:#66d9ef">False</span>)
</span></span><span style="display:flex;"><span>        (<span style="color:#ae81ff">5</span>): BatchNorm2d(<span style="color:#ae81ff">128</span>, eps<span style="color:#f92672">=</span><span style="color:#ae81ff">0.001</span>, momentum<span style="color:#f92672">=</span><span style="color:#ae81ff">0.01</span>, affine<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>, track_running_stats<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>)
</span></span><span style="display:flex;"><span>        (<span style="color:#ae81ff">6</span>): ReLU()
</span></span><span style="display:flex;"><span>        (<span style="color:#ae81ff">7</span>): Conv2d(<span style="color:#ae81ff">128</span>, <span style="color:#ae81ff">128</span>, kernel_size<span style="color:#f92672">=</span>(<span style="color:#ae81ff">3</span>, <span style="color:#ae81ff">3</span>), stride<span style="color:#f92672">=</span>(<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>), padding<span style="color:#f92672">=</span>(<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>), bias<span style="color:#f92672">=</span><span style="color:#66d9ef">False</span>)
</span></span><span style="display:flex;"><span>        (<span style="color:#ae81ff">8</span>): BatchNorm2d(<span style="color:#ae81ff">128</span>, eps<span style="color:#f92672">=</span><span style="color:#ae81ff">0.001</span>, momentum<span style="color:#f92672">=</span><span style="color:#ae81ff">0.01</span>, affine<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>, track_running_stats<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>)
</span></span><span style="display:flex;"><span>        (<span style="color:#ae81ff">9</span>): ReLU()
</span></span><span style="display:flex;"><span>        (<span style="color:#ae81ff">10</span>): Conv2d(<span style="color:#ae81ff">128</span>, <span style="color:#ae81ff">128</span>, kernel_size<span style="color:#f92672">=</span>(<span style="color:#ae81ff">3</span>, <span style="color:#ae81ff">3</span>), stride<span style="color:#f92672">=</span>(<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>), padding<span style="color:#f92672">=</span>(<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>), bias<span style="color:#f92672">=</span><span style="color:#66d9ef">False</span>)
</span></span><span style="display:flex;"><span>        (<span style="color:#ae81ff">11</span>): BatchNorm2d(<span style="color:#ae81ff">128</span>, eps<span style="color:#f92672">=</span><span style="color:#ae81ff">0.001</span>, momentum<span style="color:#f92672">=</span><span style="color:#ae81ff">0.01</span>, affine<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>, track_running_stats<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>)
</span></span><span style="display:flex;"><span>        (<span style="color:#ae81ff">12</span>): ReLU()
</span></span><span style="display:flex;"><span>        (<span style="color:#ae81ff">13</span>): Conv2d(<span style="color:#ae81ff">128</span>, <span style="color:#ae81ff">128</span>, kernel_size<span style="color:#f92672">=</span>(<span style="color:#ae81ff">3</span>, <span style="color:#ae81ff">3</span>), stride<span style="color:#f92672">=</span>(<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>), padding<span style="color:#f92672">=</span>(<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>), bias<span style="color:#f92672">=</span><span style="color:#66d9ef">False</span>)
</span></span><span style="display:flex;"><span>        (<span style="color:#ae81ff">14</span>): BatchNorm2d(<span style="color:#ae81ff">128</span>, eps<span style="color:#f92672">=</span><span style="color:#ae81ff">0.001</span>, momentum<span style="color:#f92672">=</span><span style="color:#ae81ff">0.01</span>, affine<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>, track_running_stats<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>)
</span></span><span style="display:flex;"><span>        (<span style="color:#ae81ff">15</span>): ReLU()
</span></span><span style="display:flex;"><span>        (<span style="color:#ae81ff">16</span>): Conv2d(<span style="color:#ae81ff">128</span>, <span style="color:#ae81ff">128</span>, kernel_size<span style="color:#f92672">=</span>(<span style="color:#ae81ff">3</span>, <span style="color:#ae81ff">3</span>), stride<span style="color:#f92672">=</span>(<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>), padding<span style="color:#f92672">=</span>(<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>), bias<span style="color:#f92672">=</span><span style="color:#66d9ef">False</span>)
</span></span><span style="display:flex;"><span>        (<span style="color:#ae81ff">17</span>): BatchNorm2d(<span style="color:#ae81ff">128</span>, eps<span style="color:#f92672">=</span><span style="color:#ae81ff">0.001</span>, momentum<span style="color:#f92672">=</span><span style="color:#ae81ff">0.01</span>, affine<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>, track_running_stats<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>)
</span></span><span style="display:flex;"><span>        (<span style="color:#ae81ff">18</span>): ReLU()
</span></span><span style="display:flex;"><span>      )
</span></span><span style="display:flex;"><span>      (<span style="color:#ae81ff">1</span>): Sequential(
</span></span><span style="display:flex;"><span>        (<span style="color:#ae81ff">0</span>): ZeroPad2d((<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>))
</span></span><span style="display:flex;"><span>        (<span style="color:#ae81ff">1</span>): Conv2d(<span style="color:#ae81ff">128</span>, <span style="color:#ae81ff">256</span>, kernel_size<span style="color:#f92672">=</span>(<span style="color:#ae81ff">3</span>, <span style="color:#ae81ff">3</span>), stride<span style="color:#f92672">=</span>(<span style="color:#ae81ff">2</span>, <span style="color:#ae81ff">2</span>), bias<span style="color:#f92672">=</span><span style="color:#66d9ef">False</span>)
</span></span><span style="display:flex;"><span>        (<span style="color:#ae81ff">2</span>): BatchNorm2d(<span style="color:#ae81ff">256</span>, eps<span style="color:#f92672">=</span><span style="color:#ae81ff">0.001</span>, momentum<span style="color:#f92672">=</span><span style="color:#ae81ff">0.01</span>, affine<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>, track_running_stats<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>)
</span></span><span style="display:flex;"><span>        (<span style="color:#ae81ff">3</span>): ReLU()
</span></span><span style="display:flex;"><span>        (<span style="color:#ae81ff">4</span>): Conv2d(<span style="color:#ae81ff">256</span>, <span style="color:#ae81ff">256</span>, kernel_size<span style="color:#f92672">=</span>(<span style="color:#ae81ff">3</span>, <span style="color:#ae81ff">3</span>), stride<span style="color:#f92672">=</span>(<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>), padding<span style="color:#f92672">=</span>(<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>), bias<span style="color:#f92672">=</span><span style="color:#66d9ef">False</span>)
</span></span><span style="display:flex;"><span>        (<span style="color:#ae81ff">5</span>): BatchNorm2d(<span style="color:#ae81ff">256</span>, eps<span style="color:#f92672">=</span><span style="color:#ae81ff">0.001</span>, momentum<span style="color:#f92672">=</span><span style="color:#ae81ff">0.01</span>, affine<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>, track_running_stats<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>)
</span></span><span style="display:flex;"><span>        (<span style="color:#ae81ff">6</span>): ReLU()
</span></span><span style="display:flex;"><span>        (<span style="color:#ae81ff">7</span>): Conv2d(<span style="color:#ae81ff">256</span>, <span style="color:#ae81ff">256</span>, kernel_size<span style="color:#f92672">=</span>(<span style="color:#ae81ff">3</span>, <span style="color:#ae81ff">3</span>), stride<span style="color:#f92672">=</span>(<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>), padding<span style="color:#f92672">=</span>(<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>), bias<span style="color:#f92672">=</span><span style="color:#66d9ef">False</span>)
</span></span><span style="display:flex;"><span>        (<span style="color:#ae81ff">8</span>): BatchNorm2d(<span style="color:#ae81ff">256</span>, eps<span style="color:#f92672">=</span><span style="color:#ae81ff">0.001</span>, momentum<span style="color:#f92672">=</span><span style="color:#ae81ff">0.01</span>, affine<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>, track_running_stats<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>)
</span></span><span style="display:flex;"><span>        (<span style="color:#ae81ff">9</span>): ReLU()
</span></span><span style="display:flex;"><span>        (<span style="color:#ae81ff">10</span>): Conv2d(<span style="color:#ae81ff">256</span>, <span style="color:#ae81ff">256</span>, kernel_size<span style="color:#f92672">=</span>(<span style="color:#ae81ff">3</span>, <span style="color:#ae81ff">3</span>), stride<span style="color:#f92672">=</span>(<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>), padding<span style="color:#f92672">=</span>(<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>), bias<span style="color:#f92672">=</span><span style="color:#66d9ef">False</span>)
</span></span><span style="display:flex;"><span>        (<span style="color:#ae81ff">11</span>): BatchNorm2d(<span style="color:#ae81ff">256</span>, eps<span style="color:#f92672">=</span><span style="color:#ae81ff">0.001</span>, momentum<span style="color:#f92672">=</span><span style="color:#ae81ff">0.01</span>, affine<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>, track_running_stats<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>)
</span></span><span style="display:flex;"><span>        (<span style="color:#ae81ff">12</span>): ReLU()
</span></span><span style="display:flex;"><span>        (<span style="color:#ae81ff">13</span>): Conv2d(<span style="color:#ae81ff">256</span>, <span style="color:#ae81ff">256</span>, kernel_size<span style="color:#f92672">=</span>(<span style="color:#ae81ff">3</span>, <span style="color:#ae81ff">3</span>), stride<span style="color:#f92672">=</span>(<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>), padding<span style="color:#f92672">=</span>(<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>), bias<span style="color:#f92672">=</span><span style="color:#66d9ef">False</span>)
</span></span><span style="display:flex;"><span>        (<span style="color:#ae81ff">14</span>): BatchNorm2d(<span style="color:#ae81ff">256</span>, eps<span style="color:#f92672">=</span><span style="color:#ae81ff">0.001</span>, momentum<span style="color:#f92672">=</span><span style="color:#ae81ff">0.01</span>, affine<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>, track_running_stats<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>)
</span></span><span style="display:flex;"><span>        (<span style="color:#ae81ff">15</span>): ReLU()
</span></span><span style="display:flex;"><span>        (<span style="color:#ae81ff">16</span>): Conv2d(<span style="color:#ae81ff">256</span>, <span style="color:#ae81ff">256</span>, kernel_size<span style="color:#f92672">=</span>(<span style="color:#ae81ff">3</span>, <span style="color:#ae81ff">3</span>), stride<span style="color:#f92672">=</span>(<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>), padding<span style="color:#f92672">=</span>(<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>), bias<span style="color:#f92672">=</span><span style="color:#66d9ef">False</span>)
</span></span><span style="display:flex;"><span>        (<span style="color:#ae81ff">17</span>): BatchNorm2d(<span style="color:#ae81ff">256</span>, eps<span style="color:#f92672">=</span><span style="color:#ae81ff">0.001</span>, momentum<span style="color:#f92672">=</span><span style="color:#ae81ff">0.01</span>, affine<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>, track_running_stats<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>)
</span></span><span style="display:flex;"><span>        (<span style="color:#ae81ff">18</span>): ReLU()
</span></span><span style="display:flex;"><span>      )
</span></span><span style="display:flex;"><span>    )
</span></span><span style="display:flex;"><span>    (deblocks): ModuleList(
</span></span><span style="display:flex;"><span>      (<span style="color:#ae81ff">0</span>): Sequential(
</span></span><span style="display:flex;"><span>        (<span style="color:#ae81ff">0</span>): ConvTranspose2d(<span style="color:#ae81ff">128</span>, <span style="color:#ae81ff">256</span>, kernel_size<span style="color:#f92672">=</span>(<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>), stride<span style="color:#f92672">=</span>(<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>), bias<span style="color:#f92672">=</span><span style="color:#66d9ef">False</span>)
</span></span><span style="display:flex;"><span>        (<span style="color:#ae81ff">1</span>): BatchNorm2d(<span style="color:#ae81ff">256</span>, eps<span style="color:#f92672">=</span><span style="color:#ae81ff">0.001</span>, momentum<span style="color:#f92672">=</span><span style="color:#ae81ff">0.01</span>, affine<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>, track_running_stats<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>)
</span></span><span style="display:flex;"><span>        (<span style="color:#ae81ff">2</span>): ReLU()
</span></span><span style="display:flex;"><span>      )
</span></span><span style="display:flex;"><span>      (<span style="color:#ae81ff">1</span>): Sequential(
</span></span><span style="display:flex;"><span>        (<span style="color:#ae81ff">0</span>): ConvTranspose2d(<span style="color:#ae81ff">256</span>, <span style="color:#ae81ff">256</span>, kernel_size<span style="color:#f92672">=</span>(<span style="color:#ae81ff">2</span>, <span style="color:#ae81ff">2</span>), stride<span style="color:#f92672">=</span>(<span style="color:#ae81ff">2</span>, <span style="color:#ae81ff">2</span>), bias<span style="color:#f92672">=</span><span style="color:#66d9ef">False</span>)
</span></span><span style="display:flex;"><span>        (<span style="color:#ae81ff">1</span>): BatchNorm2d(<span style="color:#ae81ff">256</span>, eps<span style="color:#f92672">=</span><span style="color:#ae81ff">0.001</span>, momentum<span style="color:#f92672">=</span><span style="color:#ae81ff">0.01</span>, affine<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>, track_running_stats<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>)
</span></span><span style="display:flex;"><span>        (<span style="color:#ae81ff">2</span>): ReLU()
</span></span><span style="display:flex;"><span>      )
</span></span><span style="display:flex;"><span>    )
</span></span><span style="display:flex;"><span>  )
</span></span><span style="display:flex;"><span>  (dense_head): CenterHead(
</span></span><span style="display:flex;"><span>    (shared_conv): Sequential(
</span></span><span style="display:flex;"><span>      (<span style="color:#ae81ff">0</span>): Conv2d(<span style="color:#ae81ff">512</span>, <span style="color:#ae81ff">64</span>, kernel_size<span style="color:#f92672">=</span>(<span style="color:#ae81ff">3</span>, <span style="color:#ae81ff">3</span>), stride<span style="color:#f92672">=</span>(<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>), padding<span style="color:#f92672">=</span>(<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>))
</span></span><span style="display:flex;"><span>      (<span style="color:#ae81ff">1</span>): BatchNorm2d(<span style="color:#ae81ff">64</span>, eps<span style="color:#f92672">=</span><span style="color:#ae81ff">1e-05</span>, momentum<span style="color:#f92672">=</span><span style="color:#ae81ff">0.1</span>, affine<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>, track_running_stats<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>)
</span></span><span style="display:flex;"><span>      (<span style="color:#ae81ff">2</span>): ReLU()
</span></span><span style="display:flex;"><span>    )
</span></span><span style="display:flex;"><span>    (heads_list): ModuleList(
</span></span><span style="display:flex;"><span>      (<span style="color:#ae81ff">0</span>): SeparateHead(
</span></span><span style="display:flex;"><span>        (center): Sequential(
</span></span><span style="display:flex;"><span>          (<span style="color:#ae81ff">0</span>): Sequential(
</span></span><span style="display:flex;"><span>            (<span style="color:#ae81ff">0</span>): Conv2d(<span style="color:#ae81ff">64</span>, <span style="color:#ae81ff">64</span>, kernel_size<span style="color:#f92672">=</span>(<span style="color:#ae81ff">3</span>, <span style="color:#ae81ff">3</span>), stride<span style="color:#f92672">=</span>(<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>), padding<span style="color:#f92672">=</span>(<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>))
</span></span><span style="display:flex;"><span>            (<span style="color:#ae81ff">1</span>): BatchNorm2d(<span style="color:#ae81ff">64</span>, eps<span style="color:#f92672">=</span><span style="color:#ae81ff">1e-05</span>, momentum<span style="color:#f92672">=</span><span style="color:#ae81ff">0.1</span>, affine<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>, track_running_stats<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>)
</span></span><span style="display:flex;"><span>            (<span style="color:#ae81ff">2</span>): ReLU()
</span></span><span style="display:flex;"><span>          )
</span></span><span style="display:flex;"><span>          (<span style="color:#ae81ff">1</span>): Conv2d(<span style="color:#ae81ff">64</span>, <span style="color:#ae81ff">2</span>, kernel_size<span style="color:#f92672">=</span>(<span style="color:#ae81ff">3</span>, <span style="color:#ae81ff">3</span>), stride<span style="color:#f92672">=</span>(<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>), padding<span style="color:#f92672">=</span>(<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>))
</span></span><span style="display:flex;"><span>        )
</span></span><span style="display:flex;"><span>        (center_z): Sequential(
</span></span><span style="display:flex;"><span>          (<span style="color:#ae81ff">0</span>): Sequential(
</span></span><span style="display:flex;"><span>            (<span style="color:#ae81ff">0</span>): Conv2d(<span style="color:#ae81ff">64</span>, <span style="color:#ae81ff">64</span>, kernel_size<span style="color:#f92672">=</span>(<span style="color:#ae81ff">3</span>, <span style="color:#ae81ff">3</span>), stride<span style="color:#f92672">=</span>(<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>), padding<span style="color:#f92672">=</span>(<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>))
</span></span><span style="display:flex;"><span>            (<span style="color:#ae81ff">1</span>): BatchNorm2d(<span style="color:#ae81ff">64</span>, eps<span style="color:#f92672">=</span><span style="color:#ae81ff">1e-05</span>, momentum<span style="color:#f92672">=</span><span style="color:#ae81ff">0.1</span>, affine<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>, track_running_stats<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>)
</span></span><span style="display:flex;"><span>            (<span style="color:#ae81ff">2</span>): ReLU()
</span></span><span style="display:flex;"><span>          )
</span></span><span style="display:flex;"><span>          (<span style="color:#ae81ff">1</span>): Conv2d(<span style="color:#ae81ff">64</span>, <span style="color:#ae81ff">1</span>, kernel_size<span style="color:#f92672">=</span>(<span style="color:#ae81ff">3</span>, <span style="color:#ae81ff">3</span>), stride<span style="color:#f92672">=</span>(<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>), padding<span style="color:#f92672">=</span>(<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>))
</span></span><span style="display:flex;"><span>        )
</span></span><span style="display:flex;"><span>        (dim): Sequential(
</span></span><span style="display:flex;"><span>          (<span style="color:#ae81ff">0</span>): Sequential(
</span></span><span style="display:flex;"><span>            (<span style="color:#ae81ff">0</span>): Conv2d(<span style="color:#ae81ff">64</span>, <span style="color:#ae81ff">64</span>, kernel_size<span style="color:#f92672">=</span>(<span style="color:#ae81ff">3</span>, <span style="color:#ae81ff">3</span>), stride<span style="color:#f92672">=</span>(<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>), padding<span style="color:#f92672">=</span>(<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>))
</span></span><span style="display:flex;"><span>            (<span style="color:#ae81ff">1</span>): BatchNorm2d(<span style="color:#ae81ff">64</span>, eps<span style="color:#f92672">=</span><span style="color:#ae81ff">1e-05</span>, momentum<span style="color:#f92672">=</span><span style="color:#ae81ff">0.1</span>, affine<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>, track_running_stats<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>)
</span></span><span style="display:flex;"><span>            (<span style="color:#ae81ff">2</span>): ReLU()
</span></span><span style="display:flex;"><span>          )
</span></span><span style="display:flex;"><span>          (<span style="color:#ae81ff">1</span>): Conv2d(<span style="color:#ae81ff">64</span>, <span style="color:#ae81ff">3</span>, kernel_size<span style="color:#f92672">=</span>(<span style="color:#ae81ff">3</span>, <span style="color:#ae81ff">3</span>), stride<span style="color:#f92672">=</span>(<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>), padding<span style="color:#f92672">=</span>(<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>))
</span></span><span style="display:flex;"><span>        )
</span></span><span style="display:flex;"><span>        (rot): Sequential(
</span></span><span style="display:flex;"><span>          (<span style="color:#ae81ff">0</span>): Sequential(
</span></span><span style="display:flex;"><span>            (<span style="color:#ae81ff">0</span>): Conv2d(<span style="color:#ae81ff">64</span>, <span style="color:#ae81ff">64</span>, kernel_size<span style="color:#f92672">=</span>(<span style="color:#ae81ff">3</span>, <span style="color:#ae81ff">3</span>), stride<span style="color:#f92672">=</span>(<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>), padding<span style="color:#f92672">=</span>(<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>))
</span></span><span style="display:flex;"><span>            (<span style="color:#ae81ff">1</span>): BatchNorm2d(<span style="color:#ae81ff">64</span>, eps<span style="color:#f92672">=</span><span style="color:#ae81ff">1e-05</span>, momentum<span style="color:#f92672">=</span><span style="color:#ae81ff">0.1</span>, affine<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>, track_running_stats<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>)
</span></span><span style="display:flex;"><span>            (<span style="color:#ae81ff">2</span>): ReLU()
</span></span><span style="display:flex;"><span>          )
</span></span><span style="display:flex;"><span>          (<span style="color:#ae81ff">1</span>): Conv2d(<span style="color:#ae81ff">64</span>, <span style="color:#ae81ff">2</span>, kernel_size<span style="color:#f92672">=</span>(<span style="color:#ae81ff">3</span>, <span style="color:#ae81ff">3</span>), stride<span style="color:#f92672">=</span>(<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>), padding<span style="color:#f92672">=</span>(<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>))
</span></span><span style="display:flex;"><span>        )
</span></span><span style="display:flex;"><span>        (vel): Sequential(
</span></span><span style="display:flex;"><span>          (<span style="color:#ae81ff">0</span>): Sequential(
</span></span><span style="display:flex;"><span>            (<span style="color:#ae81ff">0</span>): Conv2d(<span style="color:#ae81ff">64</span>, <span style="color:#ae81ff">64</span>, kernel_size<span style="color:#f92672">=</span>(<span style="color:#ae81ff">3</span>, <span style="color:#ae81ff">3</span>), stride<span style="color:#f92672">=</span>(<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>), padding<span style="color:#f92672">=</span>(<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>))
</span></span><span style="display:flex;"><span>            (<span style="color:#ae81ff">1</span>): BatchNorm2d(<span style="color:#ae81ff">64</span>, eps<span style="color:#f92672">=</span><span style="color:#ae81ff">1e-05</span>, momentum<span style="color:#f92672">=</span><span style="color:#ae81ff">0.1</span>, affine<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>, track_running_stats<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>)
</span></span><span style="display:flex;"><span>            (<span style="color:#ae81ff">2</span>): ReLU()
</span></span><span style="display:flex;"><span>          )
</span></span><span style="display:flex;"><span>          (<span style="color:#ae81ff">1</span>): Conv2d(<span style="color:#ae81ff">64</span>, <span style="color:#ae81ff">2</span>, kernel_size<span style="color:#f92672">=</span>(<span style="color:#ae81ff">3</span>, <span style="color:#ae81ff">3</span>), stride<span style="color:#f92672">=</span>(<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>), padding<span style="color:#f92672">=</span>(<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>))
</span></span><span style="display:flex;"><span>        )
</span></span><span style="display:flex;"><span>        (hm): Sequential(
</span></span><span style="display:flex;"><span>          (<span style="color:#ae81ff">0</span>): Sequential(
</span></span><span style="display:flex;"><span>            (<span style="color:#ae81ff">0</span>): Conv2d(<span style="color:#ae81ff">64</span>, <span style="color:#ae81ff">64</span>, kernel_size<span style="color:#f92672">=</span>(<span style="color:#ae81ff">3</span>, <span style="color:#ae81ff">3</span>), stride<span style="color:#f92672">=</span>(<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>), padding<span style="color:#f92672">=</span>(<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>))
</span></span><span style="display:flex;"><span>            (<span style="color:#ae81ff">1</span>): BatchNorm2d(<span style="color:#ae81ff">64</span>, eps<span style="color:#f92672">=</span><span style="color:#ae81ff">1e-05</span>, momentum<span style="color:#f92672">=</span><span style="color:#ae81ff">0.1</span>, affine<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>, track_running_stats<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>)
</span></span><span style="display:flex;"><span>            (<span style="color:#ae81ff">2</span>): ReLU()
</span></span><span style="display:flex;"><span>          )
</span></span><span style="display:flex;"><span>          (<span style="color:#ae81ff">1</span>): Conv2d(<span style="color:#ae81ff">64</span>, <span style="color:#ae81ff">1</span>, kernel_size<span style="color:#f92672">=</span>(<span style="color:#ae81ff">3</span>, <span style="color:#ae81ff">3</span>), stride<span style="color:#f92672">=</span>(<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>), padding<span style="color:#f92672">=</span>(<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>))
</span></span><span style="display:flex;"><span>        )
</span></span><span style="display:flex;"><span>      )
</span></span><span style="display:flex;"><span>      (<span style="color:#ae81ff">1</span><span style="color:#f92672">-</span><span style="color:#ae81ff">2</span>): <span style="color:#ae81ff">2</span> x SeparateHead(
</span></span><span style="display:flex;"><span>        (center): Sequential(
</span></span><span style="display:flex;"><span>          (<span style="color:#ae81ff">0</span>): Sequential(
</span></span><span style="display:flex;"><span>            (<span style="color:#ae81ff">0</span>): Conv2d(<span style="color:#ae81ff">64</span>, <span style="color:#ae81ff">64</span>, kernel_size<span style="color:#f92672">=</span>(<span style="color:#ae81ff">3</span>, <span style="color:#ae81ff">3</span>), stride<span style="color:#f92672">=</span>(<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>), padding<span style="color:#f92672">=</span>(<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>))
</span></span><span style="display:flex;"><span>            (<span style="color:#ae81ff">1</span>): BatchNorm2d(<span style="color:#ae81ff">64</span>, eps<span style="color:#f92672">=</span><span style="color:#ae81ff">1e-05</span>, momentum<span style="color:#f92672">=</span><span style="color:#ae81ff">0.1</span>, affine<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>, track_running_stats<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>)
</span></span><span style="display:flex;"><span>            (<span style="color:#ae81ff">2</span>): ReLU()
</span></span><span style="display:flex;"><span>          )
</span></span><span style="display:flex;"><span>          (<span style="color:#ae81ff">1</span>): Conv2d(<span style="color:#ae81ff">64</span>, <span style="color:#ae81ff">2</span>, kernel_size<span style="color:#f92672">=</span>(<span style="color:#ae81ff">3</span>, <span style="color:#ae81ff">3</span>), stride<span style="color:#f92672">=</span>(<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>), padding<span style="color:#f92672">=</span>(<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>))
</span></span><span style="display:flex;"><span>        )
</span></span><span style="display:flex;"><span>        (center_z): Sequential(
</span></span><span style="display:flex;"><span>          (<span style="color:#ae81ff">0</span>): Sequential(
</span></span><span style="display:flex;"><span>            (<span style="color:#ae81ff">0</span>): Conv2d(<span style="color:#ae81ff">64</span>, <span style="color:#ae81ff">64</span>, kernel_size<span style="color:#f92672">=</span>(<span style="color:#ae81ff">3</span>, <span style="color:#ae81ff">3</span>), stride<span style="color:#f92672">=</span>(<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>), padding<span style="color:#f92672">=</span>(<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>))
</span></span><span style="display:flex;"><span>            (<span style="color:#ae81ff">1</span>): BatchNorm2d(<span style="color:#ae81ff">64</span>, eps<span style="color:#f92672">=</span><span style="color:#ae81ff">1e-05</span>, momentum<span style="color:#f92672">=</span><span style="color:#ae81ff">0.1</span>, affine<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>, track_running_stats<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>)
</span></span><span style="display:flex;"><span>            (<span style="color:#ae81ff">2</span>): ReLU()
</span></span><span style="display:flex;"><span>          )
</span></span><span style="display:flex;"><span>          (<span style="color:#ae81ff">1</span>): Conv2d(<span style="color:#ae81ff">64</span>, <span style="color:#ae81ff">1</span>, kernel_size<span style="color:#f92672">=</span>(<span style="color:#ae81ff">3</span>, <span style="color:#ae81ff">3</span>), stride<span style="color:#f92672">=</span>(<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>), padding<span style="color:#f92672">=</span>(<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>))
</span></span><span style="display:flex;"><span>        )
</span></span><span style="display:flex;"><span>        (dim): Sequential(
</span></span><span style="display:flex;"><span>          (<span style="color:#ae81ff">0</span>): Sequential(
</span></span><span style="display:flex;"><span>            (<span style="color:#ae81ff">0</span>): Conv2d(<span style="color:#ae81ff">64</span>, <span style="color:#ae81ff">64</span>, kernel_size<span style="color:#f92672">=</span>(<span style="color:#ae81ff">3</span>, <span style="color:#ae81ff">3</span>), stride<span style="color:#f92672">=</span>(<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>), padding<span style="color:#f92672">=</span>(<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>))
</span></span><span style="display:flex;"><span>            (<span style="color:#ae81ff">1</span>): BatchNorm2d(<span style="color:#ae81ff">64</span>, eps<span style="color:#f92672">=</span><span style="color:#ae81ff">1e-05</span>, momentum<span style="color:#f92672">=</span><span style="color:#ae81ff">0.1</span>, affine<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>, track_running_stats<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>)
</span></span><span style="display:flex;"><span>            (<span style="color:#ae81ff">2</span>): ReLU()
</span></span><span style="display:flex;"><span>          )
</span></span><span style="display:flex;"><span>          (<span style="color:#ae81ff">1</span>): Conv2d(<span style="color:#ae81ff">64</span>, <span style="color:#ae81ff">3</span>, kernel_size<span style="color:#f92672">=</span>(<span style="color:#ae81ff">3</span>, <span style="color:#ae81ff">3</span>), stride<span style="color:#f92672">=</span>(<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>), padding<span style="color:#f92672">=</span>(<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>))
</span></span><span style="display:flex;"><span>        )
</span></span><span style="display:flex;"><span>        (rot): Sequential(
</span></span><span style="display:flex;"><span>          (<span style="color:#ae81ff">0</span>): Sequential(
</span></span><span style="display:flex;"><span>            (<span style="color:#ae81ff">0</span>): Conv2d(<span style="color:#ae81ff">64</span>, <span style="color:#ae81ff">64</span>, kernel_size<span style="color:#f92672">=</span>(<span style="color:#ae81ff">3</span>, <span style="color:#ae81ff">3</span>), stride<span style="color:#f92672">=</span>(<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>), padding<span style="color:#f92672">=</span>(<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>))
</span></span><span style="display:flex;"><span>            (<span style="color:#ae81ff">1</span>): BatchNorm2d(<span style="color:#ae81ff">64</span>, eps<span style="color:#f92672">=</span><span style="color:#ae81ff">1e-05</span>, momentum<span style="color:#f92672">=</span><span style="color:#ae81ff">0.1</span>, affine<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>, track_running_stats<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>)
</span></span><span style="display:flex;"><span>            (<span style="color:#ae81ff">2</span>): ReLU()
</span></span><span style="display:flex;"><span>          )
</span></span><span style="display:flex;"><span>          (<span style="color:#ae81ff">1</span>): Conv2d(<span style="color:#ae81ff">64</span>, <span style="color:#ae81ff">2</span>, kernel_size<span style="color:#f92672">=</span>(<span style="color:#ae81ff">3</span>, <span style="color:#ae81ff">3</span>), stride<span style="color:#f92672">=</span>(<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>), padding<span style="color:#f92672">=</span>(<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>))
</span></span><span style="display:flex;"><span>        )
</span></span><span style="display:flex;"><span>        (vel): Sequential(
</span></span><span style="display:flex;"><span>          (<span style="color:#ae81ff">0</span>): Sequential(
</span></span><span style="display:flex;"><span>            (<span style="color:#ae81ff">0</span>): Conv2d(<span style="color:#ae81ff">64</span>, <span style="color:#ae81ff">64</span>, kernel_size<span style="color:#f92672">=</span>(<span style="color:#ae81ff">3</span>, <span style="color:#ae81ff">3</span>), stride<span style="color:#f92672">=</span>(<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>), padding<span style="color:#f92672">=</span>(<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>))
</span></span><span style="display:flex;"><span>            (<span style="color:#ae81ff">1</span>): BatchNorm2d(<span style="color:#ae81ff">64</span>, eps<span style="color:#f92672">=</span><span style="color:#ae81ff">1e-05</span>, momentum<span style="color:#f92672">=</span><span style="color:#ae81ff">0.1</span>, affine<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>, track_running_stats<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>)
</span></span><span style="display:flex;"><span>            (<span style="color:#ae81ff">2</span>): ReLU()
</span></span><span style="display:flex;"><span>          )
</span></span><span style="display:flex;"><span>          (<span style="color:#ae81ff">1</span>): Conv2d(<span style="color:#ae81ff">64</span>, <span style="color:#ae81ff">2</span>, kernel_size<span style="color:#f92672">=</span>(<span style="color:#ae81ff">3</span>, <span style="color:#ae81ff">3</span>), stride<span style="color:#f92672">=</span>(<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>), padding<span style="color:#f92672">=</span>(<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>))
</span></span><span style="display:flex;"><span>        )
</span></span><span style="display:flex;"><span>        (hm): Sequential(
</span></span><span style="display:flex;"><span>          (<span style="color:#ae81ff">0</span>): Sequential(
</span></span><span style="display:flex;"><span>            (<span style="color:#ae81ff">0</span>): Conv2d(<span style="color:#ae81ff">64</span>, <span style="color:#ae81ff">64</span>, kernel_size<span style="color:#f92672">=</span>(<span style="color:#ae81ff">3</span>, <span style="color:#ae81ff">3</span>), stride<span style="color:#f92672">=</span>(<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>), padding<span style="color:#f92672">=</span>(<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>))
</span></span><span style="display:flex;"><span>            (<span style="color:#ae81ff">1</span>): BatchNorm2d(<span style="color:#ae81ff">64</span>, eps<span style="color:#f92672">=</span><span style="color:#ae81ff">1e-05</span>, momentum<span style="color:#f92672">=</span><span style="color:#ae81ff">0.1</span>, affine<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>, track_running_stats<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>)
</span></span><span style="display:flex;"><span>            (<span style="color:#ae81ff">2</span>): ReLU()
</span></span><span style="display:flex;"><span>          )
</span></span><span style="display:flex;"><span>          (<span style="color:#ae81ff">1</span>): Conv2d(<span style="color:#ae81ff">64</span>, <span style="color:#ae81ff">2</span>, kernel_size<span style="color:#f92672">=</span>(<span style="color:#ae81ff">3</span>, <span style="color:#ae81ff">3</span>), stride<span style="color:#f92672">=</span>(<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>), padding<span style="color:#f92672">=</span>(<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>))
</span></span><span style="display:flex;"><span>        )
</span></span><span style="display:flex;"><span>      )
</span></span><span style="display:flex;"><span>      (<span style="color:#ae81ff">3</span>): SeparateHead(
</span></span><span style="display:flex;"><span>        (center): Sequential(
</span></span><span style="display:flex;"><span>          (<span style="color:#ae81ff">0</span>): Sequential(
</span></span><span style="display:flex;"><span>            (<span style="color:#ae81ff">0</span>): Conv2d(<span style="color:#ae81ff">64</span>, <span style="color:#ae81ff">64</span>, kernel_size<span style="color:#f92672">=</span>(<span style="color:#ae81ff">3</span>, <span style="color:#ae81ff">3</span>), stride<span style="color:#f92672">=</span>(<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>), padding<span style="color:#f92672">=</span>(<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>))
</span></span><span style="display:flex;"><span>            (<span style="color:#ae81ff">1</span>): BatchNorm2d(<span style="color:#ae81ff">64</span>, eps<span style="color:#f92672">=</span><span style="color:#ae81ff">1e-05</span>, momentum<span style="color:#f92672">=</span><span style="color:#ae81ff">0.1</span>, affine<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>, track_running_stats<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>)
</span></span><span style="display:flex;"><span>            (<span style="color:#ae81ff">2</span>): ReLU()
</span></span><span style="display:flex;"><span>          )
</span></span><span style="display:flex;"><span>          (<span style="color:#ae81ff">1</span>): Conv2d(<span style="color:#ae81ff">64</span>, <span style="color:#ae81ff">2</span>, kernel_size<span style="color:#f92672">=</span>(<span style="color:#ae81ff">3</span>, <span style="color:#ae81ff">3</span>), stride<span style="color:#f92672">=</span>(<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>), padding<span style="color:#f92672">=</span>(<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>))
</span></span><span style="display:flex;"><span>        )
</span></span><span style="display:flex;"><span>        (center_z): Sequential(
</span></span><span style="display:flex;"><span>          (<span style="color:#ae81ff">0</span>): Sequential(
</span></span><span style="display:flex;"><span>            (<span style="color:#ae81ff">0</span>): Conv2d(<span style="color:#ae81ff">64</span>, <span style="color:#ae81ff">64</span>, kernel_size<span style="color:#f92672">=</span>(<span style="color:#ae81ff">3</span>, <span style="color:#ae81ff">3</span>), stride<span style="color:#f92672">=</span>(<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>), padding<span style="color:#f92672">=</span>(<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>))
</span></span><span style="display:flex;"><span>            (<span style="color:#ae81ff">1</span>): BatchNorm2d(<span style="color:#ae81ff">64</span>, eps<span style="color:#f92672">=</span><span style="color:#ae81ff">1e-05</span>, momentum<span style="color:#f92672">=</span><span style="color:#ae81ff">0.1</span>, affine<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>, track_running_stats<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>)
</span></span><span style="display:flex;"><span>            (<span style="color:#ae81ff">2</span>): ReLU()
</span></span><span style="display:flex;"><span>          )
</span></span><span style="display:flex;"><span>          (<span style="color:#ae81ff">1</span>): Conv2d(<span style="color:#ae81ff">64</span>, <span style="color:#ae81ff">1</span>, kernel_size<span style="color:#f92672">=</span>(<span style="color:#ae81ff">3</span>, <span style="color:#ae81ff">3</span>), stride<span style="color:#f92672">=</span>(<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>), padding<span style="color:#f92672">=</span>(<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>))
</span></span><span style="display:flex;"><span>        )
</span></span><span style="display:flex;"><span>        (dim): Sequential(
</span></span><span style="display:flex;"><span>          (<span style="color:#ae81ff">0</span>): Sequential(
</span></span><span style="display:flex;"><span>            (<span style="color:#ae81ff">0</span>): Conv2d(<span style="color:#ae81ff">64</span>, <span style="color:#ae81ff">64</span>, kernel_size<span style="color:#f92672">=</span>(<span style="color:#ae81ff">3</span>, <span style="color:#ae81ff">3</span>), stride<span style="color:#f92672">=</span>(<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>), padding<span style="color:#f92672">=</span>(<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>))
</span></span><span style="display:flex;"><span>            (<span style="color:#ae81ff">1</span>): BatchNorm2d(<span style="color:#ae81ff">64</span>, eps<span style="color:#f92672">=</span><span style="color:#ae81ff">1e-05</span>, momentum<span style="color:#f92672">=</span><span style="color:#ae81ff">0.1</span>, affine<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>, track_running_stats<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>)
</span></span><span style="display:flex;"><span>            (<span style="color:#ae81ff">2</span>): ReLU()
</span></span><span style="display:flex;"><span>          )
</span></span><span style="display:flex;"><span>          (<span style="color:#ae81ff">1</span>): Conv2d(<span style="color:#ae81ff">64</span>, <span style="color:#ae81ff">3</span>, kernel_size<span style="color:#f92672">=</span>(<span style="color:#ae81ff">3</span>, <span style="color:#ae81ff">3</span>), stride<span style="color:#f92672">=</span>(<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>), padding<span style="color:#f92672">=</span>(<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>))
</span></span><span style="display:flex;"><span>        )
</span></span><span style="display:flex;"><span>        (rot): Sequential(
</span></span><span style="display:flex;"><span>          (<span style="color:#ae81ff">0</span>): Sequential(
</span></span><span style="display:flex;"><span>            (<span style="color:#ae81ff">0</span>): Conv2d(<span style="color:#ae81ff">64</span>, <span style="color:#ae81ff">64</span>, kernel_size<span style="color:#f92672">=</span>(<span style="color:#ae81ff">3</span>, <span style="color:#ae81ff">3</span>), stride<span style="color:#f92672">=</span>(<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>), padding<span style="color:#f92672">=</span>(<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>))
</span></span><span style="display:flex;"><span>            (<span style="color:#ae81ff">1</span>): BatchNorm2d(<span style="color:#ae81ff">64</span>, eps<span style="color:#f92672">=</span><span style="color:#ae81ff">1e-05</span>, momentum<span style="color:#f92672">=</span><span style="color:#ae81ff">0.1</span>, affine<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>, track_running_stats<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>)
</span></span><span style="display:flex;"><span>            (<span style="color:#ae81ff">2</span>): ReLU()
</span></span><span style="display:flex;"><span>          )
</span></span><span style="display:flex;"><span>          (<span style="color:#ae81ff">1</span>): Conv2d(<span style="color:#ae81ff">64</span>, <span style="color:#ae81ff">2</span>, kernel_size<span style="color:#f92672">=</span>(<span style="color:#ae81ff">3</span>, <span style="color:#ae81ff">3</span>), stride<span style="color:#f92672">=</span>(<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>), padding<span style="color:#f92672">=</span>(<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>))
</span></span><span style="display:flex;"><span>        )
</span></span><span style="display:flex;"><span>        (vel): Sequential(
</span></span><span style="display:flex;"><span>          (<span style="color:#ae81ff">0</span>): Sequential(
</span></span><span style="display:flex;"><span>            (<span style="color:#ae81ff">0</span>): Conv2d(<span style="color:#ae81ff">64</span>, <span style="color:#ae81ff">64</span>, kernel_size<span style="color:#f92672">=</span>(<span style="color:#ae81ff">3</span>, <span style="color:#ae81ff">3</span>), stride<span style="color:#f92672">=</span>(<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>), padding<span style="color:#f92672">=</span>(<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>))
</span></span><span style="display:flex;"><span>            (<span style="color:#ae81ff">1</span>): BatchNorm2d(<span style="color:#ae81ff">64</span>, eps<span style="color:#f92672">=</span><span style="color:#ae81ff">1e-05</span>, momentum<span style="color:#f92672">=</span><span style="color:#ae81ff">0.1</span>, affine<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>, track_running_stats<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>)
</span></span><span style="display:flex;"><span>            (<span style="color:#ae81ff">2</span>): ReLU()
</span></span><span style="display:flex;"><span>          )
</span></span><span style="display:flex;"><span>          (<span style="color:#ae81ff">1</span>): Conv2d(<span style="color:#ae81ff">64</span>, <span style="color:#ae81ff">2</span>, kernel_size<span style="color:#f92672">=</span>(<span style="color:#ae81ff">3</span>, <span style="color:#ae81ff">3</span>), stride<span style="color:#f92672">=</span>(<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>), padding<span style="color:#f92672">=</span>(<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>))
</span></span><span style="display:flex;"><span>        )
</span></span><span style="display:flex;"><span>        (hm): Sequential(
</span></span><span style="display:flex;"><span>          (<span style="color:#ae81ff">0</span>): Sequential(
</span></span><span style="display:flex;"><span>            (<span style="color:#ae81ff">0</span>): Conv2d(<span style="color:#ae81ff">64</span>, <span style="color:#ae81ff">64</span>, kernel_size<span style="color:#f92672">=</span>(<span style="color:#ae81ff">3</span>, <span style="color:#ae81ff">3</span>), stride<span style="color:#f92672">=</span>(<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>), padding<span style="color:#f92672">=</span>(<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>))
</span></span><span style="display:flex;"><span>            (<span style="color:#ae81ff">1</span>): BatchNorm2d(<span style="color:#ae81ff">64</span>, eps<span style="color:#f92672">=</span><span style="color:#ae81ff">1e-05</span>, momentum<span style="color:#f92672">=</span><span style="color:#ae81ff">0.1</span>, affine<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>, track_running_stats<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>)
</span></span><span style="display:flex;"><span>            (<span style="color:#ae81ff">2</span>): ReLU()
</span></span><span style="display:flex;"><span>          )
</span></span><span style="display:flex;"><span>          (<span style="color:#ae81ff">1</span>): Conv2d(<span style="color:#ae81ff">64</span>, <span style="color:#ae81ff">1</span>, kernel_size<span style="color:#f92672">=</span>(<span style="color:#ae81ff">3</span>, <span style="color:#ae81ff">3</span>), stride<span style="color:#f92672">=</span>(<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>), padding<span style="color:#f92672">=</span>(<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>))
</span></span><span style="display:flex;"><span>        )
</span></span><span style="display:flex;"><span>      )
</span></span><span style="display:flex;"><span>      (<span style="color:#ae81ff">4</span><span style="color:#f92672">-</span><span style="color:#ae81ff">5</span>): <span style="color:#ae81ff">2</span> x SeparateHead(
</span></span><span style="display:flex;"><span>        (center): Sequential(
</span></span><span style="display:flex;"><span>          (<span style="color:#ae81ff">0</span>): Sequential(
</span></span><span style="display:flex;"><span>            (<span style="color:#ae81ff">0</span>): Conv2d(<span style="color:#ae81ff">64</span>, <span style="color:#ae81ff">64</span>, kernel_size<span style="color:#f92672">=</span>(<span style="color:#ae81ff">3</span>, <span style="color:#ae81ff">3</span>), stride<span style="color:#f92672">=</span>(<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>), padding<span style="color:#f92672">=</span>(<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>))
</span></span><span style="display:flex;"><span>            (<span style="color:#ae81ff">1</span>): BatchNorm2d(<span style="color:#ae81ff">64</span>, eps<span style="color:#f92672">=</span><span style="color:#ae81ff">1e-05</span>, momentum<span style="color:#f92672">=</span><span style="color:#ae81ff">0.1</span>, affine<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>, track_running_stats<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>)
</span></span><span style="display:flex;"><span>            (<span style="color:#ae81ff">2</span>): ReLU()
</span></span><span style="display:flex;"><span>          )
</span></span><span style="display:flex;"><span>          (<span style="color:#ae81ff">1</span>): Conv2d(<span style="color:#ae81ff">64</span>, <span style="color:#ae81ff">2</span>, kernel_size<span style="color:#f92672">=</span>(<span style="color:#ae81ff">3</span>, <span style="color:#ae81ff">3</span>), stride<span style="color:#f92672">=</span>(<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>), padding<span style="color:#f92672">=</span>(<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>))
</span></span><span style="display:flex;"><span>        )
</span></span><span style="display:flex;"><span>        (center_z): Sequential(
</span></span><span style="display:flex;"><span>          (<span style="color:#ae81ff">0</span>): Sequential(
</span></span><span style="display:flex;"><span>            (<span style="color:#ae81ff">0</span>): Conv2d(<span style="color:#ae81ff">64</span>, <span style="color:#ae81ff">64</span>, kernel_size<span style="color:#f92672">=</span>(<span style="color:#ae81ff">3</span>, <span style="color:#ae81ff">3</span>), stride<span style="color:#f92672">=</span>(<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>), padding<span style="color:#f92672">=</span>(<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>))
</span></span><span style="display:flex;"><span>            (<span style="color:#ae81ff">1</span>): BatchNorm2d(<span style="color:#ae81ff">64</span>, eps<span style="color:#f92672">=</span><span style="color:#ae81ff">1e-05</span>, momentum<span style="color:#f92672">=</span><span style="color:#ae81ff">0.1</span>, affine<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>, track_running_stats<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>)
</span></span><span style="display:flex;"><span>            (<span style="color:#ae81ff">2</span>): ReLU()
</span></span><span style="display:flex;"><span>          )
</span></span><span style="display:flex;"><span>          (<span style="color:#ae81ff">1</span>): Conv2d(<span style="color:#ae81ff">64</span>, <span style="color:#ae81ff">1</span>, kernel_size<span style="color:#f92672">=</span>(<span style="color:#ae81ff">3</span>, <span style="color:#ae81ff">3</span>), stride<span style="color:#f92672">=</span>(<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>), padding<span style="color:#f92672">=</span>(<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>))
</span></span><span style="display:flex;"><span>        )
</span></span><span style="display:flex;"><span>        (dim): Sequential(
</span></span><span style="display:flex;"><span>          (<span style="color:#ae81ff">0</span>): Sequential(
</span></span><span style="display:flex;"><span>            (<span style="color:#ae81ff">0</span>): Conv2d(<span style="color:#ae81ff">64</span>, <span style="color:#ae81ff">64</span>, kernel_size<span style="color:#f92672">=</span>(<span style="color:#ae81ff">3</span>, <span style="color:#ae81ff">3</span>), stride<span style="color:#f92672">=</span>(<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>), padding<span style="color:#f92672">=</span>(<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>))
</span></span><span style="display:flex;"><span>            (<span style="color:#ae81ff">1</span>): BatchNorm2d(<span style="color:#ae81ff">64</span>, eps<span style="color:#f92672">=</span><span style="color:#ae81ff">1e-05</span>, momentum<span style="color:#f92672">=</span><span style="color:#ae81ff">0.1</span>, affine<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>, track_running_stats<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>)
</span></span><span style="display:flex;"><span>            (<span style="color:#ae81ff">2</span>): ReLU()
</span></span><span style="display:flex;"><span>          )
</span></span><span style="display:flex;"><span>          (<span style="color:#ae81ff">1</span>): Conv2d(<span style="color:#ae81ff">64</span>, <span style="color:#ae81ff">3</span>, kernel_size<span style="color:#f92672">=</span>(<span style="color:#ae81ff">3</span>, <span style="color:#ae81ff">3</span>), stride<span style="color:#f92672">=</span>(<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>), padding<span style="color:#f92672">=</span>(<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>))
</span></span><span style="display:flex;"><span>        )
</span></span><span style="display:flex;"><span>        (rot): Sequential(
</span></span><span style="display:flex;"><span>          (<span style="color:#ae81ff">0</span>): Sequential(
</span></span><span style="display:flex;"><span>            (<span style="color:#ae81ff">0</span>): Conv2d(<span style="color:#ae81ff">64</span>, <span style="color:#ae81ff">64</span>, kernel_size<span style="color:#f92672">=</span>(<span style="color:#ae81ff">3</span>, <span style="color:#ae81ff">3</span>), stride<span style="color:#f92672">=</span>(<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>), padding<span style="color:#f92672">=</span>(<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>))
</span></span><span style="display:flex;"><span>            (<span style="color:#ae81ff">1</span>): BatchNorm2d(<span style="color:#ae81ff">64</span>, eps<span style="color:#f92672">=</span><span style="color:#ae81ff">1e-05</span>, momentum<span style="color:#f92672">=</span><span style="color:#ae81ff">0.1</span>, affine<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>, track_running_stats<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>)
</span></span><span style="display:flex;"><span>            (<span style="color:#ae81ff">2</span>): ReLU()
</span></span><span style="display:flex;"><span>          )
</span></span><span style="display:flex;"><span>          (<span style="color:#ae81ff">1</span>): Conv2d(<span style="color:#ae81ff">64</span>, <span style="color:#ae81ff">2</span>, kernel_size<span style="color:#f92672">=</span>(<span style="color:#ae81ff">3</span>, <span style="color:#ae81ff">3</span>), stride<span style="color:#f92672">=</span>(<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>), padding<span style="color:#f92672">=</span>(<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>))
</span></span><span style="display:flex;"><span>        )
</span></span><span style="display:flex;"><span>        (vel): Sequential(
</span></span><span style="display:flex;"><span>          (<span style="color:#ae81ff">0</span>): Sequential(
</span></span><span style="display:flex;"><span>            (<span style="color:#ae81ff">0</span>): Conv2d(<span style="color:#ae81ff">64</span>, <span style="color:#ae81ff">64</span>, kernel_size<span style="color:#f92672">=</span>(<span style="color:#ae81ff">3</span>, <span style="color:#ae81ff">3</span>), stride<span style="color:#f92672">=</span>(<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>), padding<span style="color:#f92672">=</span>(<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>))
</span></span><span style="display:flex;"><span>            (<span style="color:#ae81ff">1</span>): BatchNorm2d(<span style="color:#ae81ff">64</span>, eps<span style="color:#f92672">=</span><span style="color:#ae81ff">1e-05</span>, momentum<span style="color:#f92672">=</span><span style="color:#ae81ff">0.1</span>, affine<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>, track_running_stats<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>)
</span></span><span style="display:flex;"><span>            (<span style="color:#ae81ff">2</span>): ReLU()
</span></span><span style="display:flex;"><span>          )
</span></span><span style="display:flex;"><span>          (<span style="color:#ae81ff">1</span>): Conv2d(<span style="color:#ae81ff">64</span>, <span style="color:#ae81ff">2</span>, kernel_size<span style="color:#f92672">=</span>(<span style="color:#ae81ff">3</span>, <span style="color:#ae81ff">3</span>), stride<span style="color:#f92672">=</span>(<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>), padding<span style="color:#f92672">=</span>(<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>))
</span></span><span style="display:flex;"><span>        )
</span></span><span style="display:flex;"><span>        (hm): Sequential(
</span></span><span style="display:flex;"><span>          (<span style="color:#ae81ff">0</span>): Sequential(
</span></span><span style="display:flex;"><span>            (<span style="color:#ae81ff">0</span>): Conv2d(<span style="color:#ae81ff">64</span>, <span style="color:#ae81ff">64</span>, kernel_size<span style="color:#f92672">=</span>(<span style="color:#ae81ff">3</span>, <span style="color:#ae81ff">3</span>), stride<span style="color:#f92672">=</span>(<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>), padding<span style="color:#f92672">=</span>(<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>))
</span></span><span style="display:flex;"><span>            (<span style="color:#ae81ff">1</span>): BatchNorm2d(<span style="color:#ae81ff">64</span>, eps<span style="color:#f92672">=</span><span style="color:#ae81ff">1e-05</span>, momentum<span style="color:#f92672">=</span><span style="color:#ae81ff">0.1</span>, affine<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>, track_running_stats<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>)
</span></span><span style="display:flex;"><span>            (<span style="color:#ae81ff">2</span>): ReLU()
</span></span><span style="display:flex;"><span>          )
</span></span><span style="display:flex;"><span>          (<span style="color:#ae81ff">1</span>): Conv2d(<span style="color:#ae81ff">64</span>, <span style="color:#ae81ff">2</span>, kernel_size<span style="color:#f92672">=</span>(<span style="color:#ae81ff">3</span>, <span style="color:#ae81ff">3</span>), stride<span style="color:#f92672">=</span>(<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>), padding<span style="color:#f92672">=</span>(<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>))
</span></span><span style="display:flex;"><span>        )
</span></span><span style="display:flex;"><span>      )
</span></span><span style="display:flex;"><span>    )
</span></span><span style="display:flex;"><span>    (hm_loss_func): FocalLossCenterNet()
</span></span><span style="display:flex;"><span>    (reg_loss_func): RegLossCenterNet()
</span></span><span style="display:flex;"><span>  )
</span></span><span style="display:flex;"><span>  (point_head): <span style="color:#66d9ef">None</span>
</span></span><span style="display:flex;"><span>  (roi_head): <span style="color:#66d9ef">None</span>
</span></span><span style="display:flex;"><span>)
</span></span></code></pre></div><p>Conclusion: compared with normal 2D object detection algorithm&rsquo;s used layers, LiDAR-based 3D object detection utilize layers like <code>SparseConv3d</code> and <code>SubMConv3d</code> to implement 3D backbone. Other layers are regular.</p>
<h4 id="3-inference-time-of-each-layer">3. Inference time of each layer<a hidden class="anchor" aria-hidden="true" href="#3-inference-time-of-each-layer">#</a></h4>
<ul>
<li>With the use of <code>Profiler</code>:</li>
</ul>
<p><img loading="lazy" src="https://s2.loli.net/2024/04/09/mq1reK3XhfT42BE.png" alt="image-20240408143118738"  />
</p>
<p>But what we get right here is the layer name of the inner framework, i.e., the function name of <code>C</code> language. Therefore, I write some simple codes to get the consuming of time of each Pytorch layer.</p>
<ul>
<li>With the use of customized code:</li>
</ul>
<p>We get top 20 time-consuming Pytorch layer:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#ae81ff">2024</span><span style="color:#f92672">-</span><span style="color:#ae81ff">04</span><span style="color:#f92672">-</span><span style="color:#ae81ff">09</span> <span style="color:#ae81ff">09</span>:<span style="color:#ae81ff">47</span>:<span style="color:#ae81ff">53</span>,<span style="color:#ae81ff">138</span>   INFO  <span style="color:#f92672">&lt;</span><span style="color:#66d9ef">class</span> <span style="color:#960050;background-color:#1e0010">&#39;</span><span style="color:#a6e22e">torch</span><span style="color:#f92672">.</span>nn<span style="color:#f92672">.</span>modules<span style="color:#f92672">.</span>conv<span style="color:#f92672">.</span>Conv2d<span style="color:#e6db74">&#39;&gt;: 0.07607173919677734 seconds</span>
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">2024</span><span style="color:#f92672">-</span><span style="color:#ae81ff">04</span><span style="color:#f92672">-</span><span style="color:#ae81ff">09</span> <span style="color:#ae81ff">09</span>:<span style="color:#ae81ff">47</span>:<span style="color:#ae81ff">53</span>,<span style="color:#ae81ff">139</span>   INFO  <span style="color:#f92672">&lt;</span><span style="color:#66d9ef">class</span> <span style="color:#960050;background-color:#1e0010">&#39;</span><span style="color:#a6e22e">spconv</span><span style="color:#f92672">.</span>pytorch<span style="color:#f92672">.</span>conv<span style="color:#f92672">.</span>SubMConv3d<span style="color:#e6db74">&#39;&gt;: 0.058701515197753906 seconds</span>
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">2024</span><span style="color:#f92672">-</span><span style="color:#ae81ff">04</span><span style="color:#f92672">-</span><span style="color:#ae81ff">09</span> <span style="color:#ae81ff">09</span>:<span style="color:#ae81ff">47</span>:<span style="color:#ae81ff">53</span>,<span style="color:#ae81ff">139</span>   INFO  <span style="color:#f92672">&lt;</span><span style="color:#66d9ef">class</span> <span style="color:#960050;background-color:#1e0010">&#39;</span><span style="color:#a6e22e">spconv</span><span style="color:#f92672">.</span>pytorch<span style="color:#f92672">.</span>conv<span style="color:#f92672">.</span>SubMConv3d<span style="color:#e6db74">&#39;&gt;: 0.038175344467163086 seconds</span>
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">2024</span><span style="color:#f92672">-</span><span style="color:#ae81ff">04</span><span style="color:#f92672">-</span><span style="color:#ae81ff">09</span> <span style="color:#ae81ff">09</span>:<span style="color:#ae81ff">47</span>:<span style="color:#ae81ff">53</span>,<span style="color:#ae81ff">139</span>   INFO  <span style="color:#f92672">&lt;</span><span style="color:#66d9ef">class</span> <span style="color:#960050;background-color:#1e0010">&#39;</span><span style="color:#a6e22e">spconv</span><span style="color:#f92672">.</span>pytorch<span style="color:#f92672">.</span>conv<span style="color:#f92672">.</span>SubMConv3d<span style="color:#e6db74">&#39;&gt;: 0.030804872512817383 seconds</span>
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">2024</span><span style="color:#f92672">-</span><span style="color:#ae81ff">04</span><span style="color:#f92672">-</span><span style="color:#ae81ff">09</span> <span style="color:#ae81ff">09</span>:<span style="color:#ae81ff">47</span>:<span style="color:#ae81ff">53</span>,<span style="color:#ae81ff">139</span>   INFO  <span style="color:#f92672">&lt;</span><span style="color:#66d9ef">class</span> <span style="color:#960050;background-color:#1e0010">&#39;</span><span style="color:#a6e22e">spconv</span><span style="color:#f92672">.</span>pytorch<span style="color:#f92672">.</span>conv<span style="color:#f92672">.</span>SparseConv3d<span style="color:#e6db74">&#39;&gt;: 0.025530099868774414 seconds</span>
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">2024</span><span style="color:#f92672">-</span><span style="color:#ae81ff">04</span><span style="color:#f92672">-</span><span style="color:#ae81ff">09</span> <span style="color:#ae81ff">09</span>:<span style="color:#ae81ff">47</span>:<span style="color:#ae81ff">53</span>,<span style="color:#ae81ff">139</span>   INFO  <span style="color:#f92672">&lt;</span><span style="color:#66d9ef">class</span> <span style="color:#960050;background-color:#1e0010">&#39;</span><span style="color:#a6e22e">spconv</span><span style="color:#f92672">.</span>pytorch<span style="color:#f92672">.</span>conv<span style="color:#f92672">.</span>SparseConv3d<span style="color:#e6db74">&#39;&gt;: 0.02077198028564453 seconds</span>
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">2024</span><span style="color:#f92672">-</span><span style="color:#ae81ff">04</span><span style="color:#f92672">-</span><span style="color:#ae81ff">09</span> <span style="color:#ae81ff">09</span>:<span style="color:#ae81ff">47</span>:<span style="color:#ae81ff">53</span>,<span style="color:#ae81ff">139</span>   INFO  <span style="color:#f92672">&lt;</span><span style="color:#66d9ef">class</span> <span style="color:#960050;background-color:#1e0010">&#39;</span><span style="color:#a6e22e">torch</span><span style="color:#f92672">.</span>nn<span style="color:#f92672">.</span>modules<span style="color:#f92672">.</span>conv<span style="color:#f92672">.</span>ConvTranspose2d<span style="color:#e6db74">&#39;&gt;: 0.020176410675048828 seconds</span>
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">2024</span><span style="color:#f92672">-</span><span style="color:#ae81ff">04</span><span style="color:#f92672">-</span><span style="color:#ae81ff">09</span> <span style="color:#ae81ff">09</span>:<span style="color:#ae81ff">47</span>:<span style="color:#ae81ff">53</span>,<span style="color:#ae81ff">139</span>   INFO  <span style="color:#f92672">&lt;</span><span style="color:#66d9ef">class</span> <span style="color:#960050;background-color:#1e0010">&#39;</span><span style="color:#a6e22e">spconv</span><span style="color:#f92672">.</span>pytorch<span style="color:#f92672">.</span>conv<span style="color:#f92672">.</span>SparseConv3d<span style="color:#e6db74">&#39;&gt;: 0.016696453094482422 seconds</span>
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">2024</span><span style="color:#f92672">-</span><span style="color:#ae81ff">04</span><span style="color:#f92672">-</span><span style="color:#ae81ff">09</span> <span style="color:#ae81ff">09</span>:<span style="color:#ae81ff">47</span>:<span style="color:#ae81ff">53</span>,<span style="color:#ae81ff">139</span>   INFO  <span style="color:#f92672">&lt;</span><span style="color:#66d9ef">class</span> <span style="color:#960050;background-color:#1e0010">&#39;</span><span style="color:#a6e22e">torch</span><span style="color:#f92672">.</span>nn<span style="color:#f92672">.</span>modules<span style="color:#f92672">.</span>conv<span style="color:#f92672">.</span>ConvTranspose2d<span style="color:#e6db74">&#39;&gt;: 0.014063358306884766 seconds</span>
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">2024</span><span style="color:#f92672">-</span><span style="color:#ae81ff">04</span><span style="color:#f92672">-</span><span style="color:#ae81ff">09</span> <span style="color:#ae81ff">09</span>:<span style="color:#ae81ff">47</span>:<span style="color:#ae81ff">53</span>,<span style="color:#ae81ff">139</span>   INFO  <span style="color:#f92672">&lt;</span><span style="color:#66d9ef">class</span> <span style="color:#960050;background-color:#1e0010">&#39;</span><span style="color:#a6e22e">spconv</span><span style="color:#f92672">.</span>pytorch<span style="color:#f92672">.</span>conv<span style="color:#f92672">.</span>SubMConv3d<span style="color:#e6db74">&#39;&gt;: 0.014019966125488281 seconds</span>
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">2024</span><span style="color:#f92672">-</span><span style="color:#ae81ff">04</span><span style="color:#f92672">-</span><span style="color:#ae81ff">09</span> <span style="color:#ae81ff">09</span>:<span style="color:#ae81ff">47</span>:<span style="color:#ae81ff">53</span>,<span style="color:#ae81ff">139</span>   INFO  <span style="color:#f92672">&lt;</span><span style="color:#66d9ef">class</span> <span style="color:#960050;background-color:#1e0010">&#39;</span><span style="color:#a6e22e">pcdet</span><span style="color:#f92672">.</span>models<span style="color:#f92672">.</span>backbones_3d<span style="color:#f92672">.</span>vfe<span style="color:#f92672">.</span>mean_vfe<span style="color:#f92672">.</span>MeanVFE<span style="color:#e6db74">&#39;&gt;: 0.012219667434692383 seconds</span>
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">2024</span><span style="color:#f92672">-</span><span style="color:#ae81ff">04</span><span style="color:#f92672">-</span><span style="color:#ae81ff">09</span> <span style="color:#ae81ff">09</span>:<span style="color:#ae81ff">47</span>:<span style="color:#ae81ff">53</span>,<span style="color:#ae81ff">139</span>   INFO  <span style="color:#f92672">&lt;</span><span style="color:#66d9ef">class</span> <span style="color:#960050;background-color:#1e0010">&#39;</span><span style="color:#a6e22e">pcdet</span><span style="color:#f92672">.</span>models<span style="color:#f92672">.</span>detectors<span style="color:#f92672">.</span>centerpoint<span style="color:#f92672">.</span>CenterPoint<span style="color:#e6db74">&#39;&gt;: 0.01217341423034668 seconds</span>
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">2024</span><span style="color:#f92672">-</span><span style="color:#ae81ff">04</span><span style="color:#f92672">-</span><span style="color:#ae81ff">09</span> <span style="color:#ae81ff">09</span>:<span style="color:#ae81ff">47</span>:<span style="color:#ae81ff">53</span>,<span style="color:#ae81ff">139</span>   INFO  <span style="color:#f92672">&lt;</span><span style="color:#66d9ef">class</span> <span style="color:#960050;background-color:#1e0010">&#39;</span><span style="color:#a6e22e">torch</span><span style="color:#f92672">.</span>nn<span style="color:#f92672">.</span>modules<span style="color:#f92672">.</span>conv<span style="color:#f92672">.</span>Conv2d<span style="color:#e6db74">&#39;&gt;: 0.009574413299560547 seconds</span>
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">2024</span><span style="color:#f92672">-</span><span style="color:#ae81ff">04</span><span style="color:#f92672">-</span><span style="color:#ae81ff">09</span> <span style="color:#ae81ff">09</span>:<span style="color:#ae81ff">47</span>:<span style="color:#ae81ff">53</span>,<span style="color:#ae81ff">139</span>   INFO  <span style="color:#f92672">&lt;</span><span style="color:#66d9ef">class</span> <span style="color:#960050;background-color:#1e0010">&#39;</span><span style="color:#a6e22e">pcdet</span><span style="color:#f92672">.</span>models<span style="color:#f92672">.</span>backbones_2d<span style="color:#f92672">.</span>map_to_bev<span style="color:#f92672">.</span>height_compression<span style="color:#f92672">.</span>HeightCompression<span style="color:#e6db74">&#39;&gt;: 0.006260395050048828 seconds</span>
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">2024</span><span style="color:#f92672">-</span><span style="color:#ae81ff">04</span><span style="color:#f92672">-</span><span style="color:#ae81ff">09</span> <span style="color:#ae81ff">09</span>:<span style="color:#ae81ff">47</span>:<span style="color:#ae81ff">53</span>,<span style="color:#ae81ff">139</span>   INFO  <span style="color:#f92672">&lt;</span><span style="color:#66d9ef">class</span> <span style="color:#960050;background-color:#1e0010">&#39;</span><span style="color:#a6e22e">spconv</span><span style="color:#f92672">.</span>pytorch<span style="color:#f92672">.</span>conv<span style="color:#f92672">.</span>SparseConv3d<span style="color:#e6db74">&#39;&gt;: 0.005869150161743164 seconds</span>
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">2024</span><span style="color:#f92672">-</span><span style="color:#ae81ff">04</span><span style="color:#f92672">-</span><span style="color:#ae81ff">09</span> <span style="color:#ae81ff">09</span>:<span style="color:#ae81ff">47</span>:<span style="color:#ae81ff">53</span>,<span style="color:#ae81ff">139</span>   INFO  <span style="color:#f92672">&lt;</span><span style="color:#66d9ef">class</span> <span style="color:#960050;background-color:#1e0010">&#39;</span><span style="color:#a6e22e">torch</span><span style="color:#f92672">.</span>nn<span style="color:#f92672">.</span>modules<span style="color:#f92672">.</span>conv<span style="color:#f92672">.</span>Conv2d<span style="color:#e6db74">&#39;&gt;: 0.003749370574951172 seconds</span>
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">2024</span><span style="color:#f92672">-</span><span style="color:#ae81ff">04</span><span style="color:#f92672">-</span><span style="color:#ae81ff">09</span> <span style="color:#ae81ff">09</span>:<span style="color:#ae81ff">47</span>:<span style="color:#ae81ff">53</span>,<span style="color:#ae81ff">139</span>   INFO  <span style="color:#f92672">&lt;</span><span style="color:#66d9ef">class</span> <span style="color:#960050;background-color:#1e0010">&#39;</span><span style="color:#a6e22e">torch</span><span style="color:#f92672">.</span>nn<span style="color:#f92672">.</span>modules<span style="color:#f92672">.</span>conv<span style="color:#f92672">.</span>Conv2d<span style="color:#e6db74">&#39;&gt;: 0.003445148468017578 seconds</span>
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">2024</span><span style="color:#f92672">-</span><span style="color:#ae81ff">04</span><span style="color:#f92672">-</span><span style="color:#ae81ff">09</span> <span style="color:#ae81ff">09</span>:<span style="color:#ae81ff">47</span>:<span style="color:#ae81ff">53</span>,<span style="color:#ae81ff">139</span>   INFO  <span style="color:#f92672">&lt;</span><span style="color:#66d9ef">class</span> <span style="color:#960050;background-color:#1e0010">&#39;</span><span style="color:#a6e22e">torch</span><span style="color:#f92672">.</span>nn<span style="color:#f92672">.</span>modules<span style="color:#f92672">.</span>conv<span style="color:#f92672">.</span>Conv2d<span style="color:#e6db74">&#39;&gt;: 0.0028769969940185547 seconds</span>
</span></span></code></pre></div><p>That is to say, the major time-consuming layer should be<code>Conv2d</code>, <code>ConvTransposed2d</code>, <code>SubMConv3d</code>, and <code>SparseConv3d</code>, which means that we can start from quantization of <code>Conv2d</code> and <code>ConvTranspose2d</code> (since <code>SubMConv3d</code> and <code>SparseConv3d</code> don&rsquo;t have pre-defined quantization class right now, but we can always customize layers afterwards).</p>
<h4 id="4-memory-usage-of-each-layer">4. Memory usage of each layer<a hidden class="anchor" aria-hidden="true" href="#4-memory-usage-of-each-layer">#</a></h4>
<p>I tried self-written hooks to figure out the GPU memory usage of each layer, but it always seems that there&rsquo;s some problem with my code. So I instead use <code>profiler</code>:</p>
<p><img loading="lazy" src="https://s2.loli.net/2024/04/09/mq1reK3XhfT42BE.png" alt="image-20240408143118738"  />
</p>
<p>As we can see from the right side, the layer which has high GPU memory usage is the <code>Sparse-Conv3d</code> from the module <code>spconv</code> (Name: <code>cumm:conv:....</code>). But I can&rsquo;t quite understand that why <code>Conv2d</code> didn&rsquo;t use any of the GPU memory while has GPU time on them (on the right side).</p>
<h4 id="5-storage-usage-of-each-layer-fvcore">5. Storage usage of each layer (fvcore)<a hidden class="anchor" aria-hidden="true" href="#5-storage-usage-of-each-layer-fvcore">#</a></h4>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">|</span> name                        <span style="color:#f92672">|</span> <span style="color:#75715e">#elements or shape   |</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">|</span>:<span style="color:#f92672">----------------------------|</span>:<span style="color:#f92672">---------------------|</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">|</span> model                       <span style="color:#f92672">|</span> <span style="color:#ae81ff">8.9</span>M                 <span style="color:#f92672">|</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">|</span>  backbone_3d                <span style="color:#f92672">|</span>  <span style="color:#ae81ff">2.7</span>M                <span style="color:#f92672">|</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">|</span>   backbone_3d<span style="color:#f92672">.</span>conv_input    <span style="color:#f92672">|</span>   <span style="color:#ae81ff">2.2</span>K               <span style="color:#f92672">|</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">|</span>    backbone_3d<span style="color:#f92672">.</span>conv_input<span style="color:#ae81ff">.0</span> <span style="color:#f92672">|</span>    <span style="color:#ae81ff">2.2</span>K              <span style="color:#f92672">|</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">|</span>    backbone_3d<span style="color:#f92672">.</span>conv_input<span style="color:#ae81ff">.1</span> <span style="color:#f92672">|</span>    <span style="color:#ae81ff">32</span>                <span style="color:#f92672">|</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">|</span>   backbone_3d<span style="color:#f92672">.</span>conv1         <span style="color:#f92672">|</span>   <span style="color:#ae81ff">27.8</span>K              <span style="color:#f92672">|</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">|</span>    backbone_3d<span style="color:#f92672">.</span>conv1<span style="color:#ae81ff">.0</span>      <span style="color:#f92672">|</span>    <span style="color:#ae81ff">13.9</span>K             <span style="color:#f92672">|</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">|</span>    backbone_3d<span style="color:#f92672">.</span>conv1<span style="color:#ae81ff">.1</span>      <span style="color:#f92672">|</span>    <span style="color:#ae81ff">13.9</span>K             <span style="color:#f92672">|</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">|</span>   backbone_3d<span style="color:#f92672">.</span>conv2         <span style="color:#f92672">|</span>   <span style="color:#ae81ff">0.1</span>M               <span style="color:#f92672">|</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">|</span>    backbone_3d<span style="color:#f92672">.</span>conv2<span style="color:#ae81ff">.0</span>      <span style="color:#f92672">|</span>    <span style="color:#ae81ff">13.9</span>K             <span style="color:#f92672">|</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">|</span>    backbone_3d<span style="color:#f92672">.</span>conv2<span style="color:#ae81ff">.1</span>      <span style="color:#f92672">|</span>    <span style="color:#ae81ff">55.5</span>K             <span style="color:#f92672">|</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">|</span>    backbone_3d<span style="color:#f92672">.</span>conv2<span style="color:#ae81ff">.2</span>      <span style="color:#f92672">|</span>    <span style="color:#ae81ff">55.5</span>K             <span style="color:#f92672">|</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">|</span>   backbone_3d<span style="color:#f92672">.</span>conv3         <span style="color:#f92672">|</span>   <span style="color:#ae81ff">0.5</span>M               <span style="color:#f92672">|</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">|</span>    backbone_3d<span style="color:#f92672">.</span>conv3<span style="color:#ae81ff">.0</span>      <span style="color:#f92672">|</span>    <span style="color:#ae81ff">55.4</span>K             <span style="color:#f92672">|</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">|</span>    backbone_3d<span style="color:#f92672">.</span>conv3<span style="color:#ae81ff">.1</span>      <span style="color:#f92672">|</span>    <span style="color:#ae81ff">0.2</span>M              <span style="color:#f92672">|</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">|</span>    backbone_3d<span style="color:#f92672">.</span>conv3<span style="color:#ae81ff">.2</span>      <span style="color:#f92672">|</span>    <span style="color:#ae81ff">0.2</span>M              <span style="color:#f92672">|</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">|</span>   backbone_3d<span style="color:#f92672">.</span>conv4         <span style="color:#f92672">|</span>   <span style="color:#ae81ff">2.0</span>M               <span style="color:#f92672">|</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">|</span>    backbone_3d<span style="color:#f92672">.</span>conv4<span style="color:#ae81ff">.0</span>      <span style="color:#f92672">|</span>    <span style="color:#ae81ff">0.2</span>M              <span style="color:#f92672">|</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">|</span>    backbone_3d<span style="color:#f92672">.</span>conv4<span style="color:#ae81ff">.1</span>      <span style="color:#f92672">|</span>    <span style="color:#ae81ff">0.9</span>M              <span style="color:#f92672">|</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">|</span>    backbone_3d<span style="color:#f92672">.</span>conv4<span style="color:#ae81ff">.2</span>      <span style="color:#f92672">|</span>    <span style="color:#ae81ff">0.9</span>M              <span style="color:#f92672">|</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">|</span>   backbone_3d<span style="color:#f92672">.</span>conv_out      <span style="color:#f92672">|</span>   <span style="color:#ae81ff">49.4</span>K              <span style="color:#f92672">|</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">|</span>    backbone_3d<span style="color:#f92672">.</span>conv_out<span style="color:#ae81ff">.0</span>   <span style="color:#f92672">|</span>    <span style="color:#ae81ff">49.2</span>K             <span style="color:#f92672">|</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">|</span>    backbone_3d<span style="color:#f92672">.</span>conv_out<span style="color:#ae81ff">.1</span>   <span style="color:#f92672">|</span>    <span style="color:#ae81ff">0.3</span>K              <span style="color:#f92672">|</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">|</span>  backbone_2d                <span style="color:#f92672">|</span>  <span style="color:#ae81ff">4.6</span>M                <span style="color:#f92672">|</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">|</span>   backbone_2d<span style="color:#f92672">.</span>blocks        <span style="color:#f92672">|</span>   <span style="color:#ae81ff">4.3</span>M               <span style="color:#f92672">|</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">|</span>    backbone_2d<span style="color:#f92672">.</span>blocks<span style="color:#ae81ff">.0</span>     <span style="color:#f92672">|</span>    <span style="color:#ae81ff">1.0</span>M              <span style="color:#f92672">|</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">|</span>    backbone_2d<span style="color:#f92672">.</span>blocks<span style="color:#ae81ff">.1</span>     <span style="color:#f92672">|</span>    <span style="color:#ae81ff">3.2</span>M              <span style="color:#f92672">|</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">|</span>   backbone_2d<span style="color:#f92672">.</span>deblocks      <span style="color:#f92672">|</span>   <span style="color:#ae81ff">0.3</span>M               <span style="color:#f92672">|</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">|</span>    backbone_2d<span style="color:#f92672">.</span>deblocks<span style="color:#ae81ff">.0</span>   <span style="color:#f92672">|</span>    <span style="color:#ae81ff">33.3</span>K             <span style="color:#f92672">|</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">|</span>    backbone_2d<span style="color:#f92672">.</span>deblocks<span style="color:#ae81ff">.1</span>   <span style="color:#f92672">|</span>    <span style="color:#ae81ff">0.3</span>M              <span style="color:#f92672">|</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">|</span>  dense_head                 <span style="color:#f92672">|</span>  <span style="color:#ae81ff">1.7</span>M                <span style="color:#f92672">|</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">|</span>   dense_head<span style="color:#f92672">.</span>shared_conv    <span style="color:#f92672">|</span>   <span style="color:#ae81ff">0.3</span>M               <span style="color:#f92672">|</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">|</span>    dense_head<span style="color:#f92672">.</span>shared_conv<span style="color:#ae81ff">.0</span> <span style="color:#f92672">|</span>    <span style="color:#ae81ff">0.3</span>M              <span style="color:#f92672">|</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">|</span>    dense_head<span style="color:#f92672">.</span>shared_conv<span style="color:#ae81ff">.1</span> <span style="color:#f92672">|</span>    <span style="color:#ae81ff">0.1</span>K              <span style="color:#f92672">|</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">|</span>   dense_head<span style="color:#f92672">.</span>heads_list     <span style="color:#f92672">|</span>   <span style="color:#ae81ff">1.4</span>M               <span style="color:#f92672">|</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">|</span>    dense_head<span style="color:#f92672">.</span>heads_list<span style="color:#ae81ff">.0</span>  <span style="color:#f92672">|</span>    <span style="color:#ae81ff">0.2</span>M              <span style="color:#f92672">|</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">|</span>    dense_head<span style="color:#f92672">.</span>heads_list<span style="color:#ae81ff">.1</span>  <span style="color:#f92672">|</span>    <span style="color:#ae81ff">0.2</span>M              <span style="color:#f92672">|</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">|</span>    dense_head<span style="color:#f92672">.</span>heads_list<span style="color:#ae81ff">.2</span>  <span style="color:#f92672">|</span>    <span style="color:#ae81ff">0.2</span>M              <span style="color:#f92672">|</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">|</span>    dense_head<span style="color:#f92672">.</span>heads_list<span style="color:#ae81ff">.3</span>  <span style="color:#f92672">|</span>    <span style="color:#ae81ff">0.2</span>M              <span style="color:#f92672">|</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">|</span>    dense_head<span style="color:#f92672">.</span>heads_list<span style="color:#ae81ff">.4</span>  <span style="color:#f92672">|</span>    <span style="color:#ae81ff">0.2</span>M              <span style="color:#f92672">|</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">|</span>    dense_head<span style="color:#f92672">.</span>heads_list<span style="color:#ae81ff">.5</span>  <span style="color:#f92672">|</span>    <span style="color:#ae81ff">0.2</span>M              <span style="color:#f92672">|</span>
</span></span></code></pre></div><p>And below is a storage diagram of a <code>ResNet-50</code>:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>Skipped operation aten::batch_norm <span style="color:#ae81ff">53</span> time(s)
</span></span><span style="display:flex;"><span>Skipped operation aten::max_pool2d <span style="color:#ae81ff">1</span> time(s)
</span></span><span style="display:flex;"><span>Skipped operation aten::add_ <span style="color:#ae81ff">16</span> time(s)
</span></span><span style="display:flex;"><span>Skipped operation aten::adaptive_avg_pool2d <span style="color:#ae81ff">1</span> time(s)
</span></span><span style="display:flex;"><span>FLOPs:  <span style="color:#ae81ff">4089184256</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">|</span> name                   <span style="color:#f92672">|</span> <span style="color:#75715e">#elements or shape   |</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">|</span>:<span style="color:#f92672">-----------------------|</span>:<span style="color:#f92672">---------------------|</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">|</span> model                  <span style="color:#f92672">|</span> <span style="color:#ae81ff">25.6</span>M                <span style="color:#f92672">|</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">|</span>  conv1                 <span style="color:#f92672">|</span>  <span style="color:#ae81ff">9.4</span>K                <span style="color:#f92672">|</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">|</span>   conv1<span style="color:#f92672">.</span>weight         <span style="color:#f92672">|</span>   (<span style="color:#ae81ff">64</span>, <span style="color:#ae81ff">3</span>, <span style="color:#ae81ff">7</span>, <span style="color:#ae81ff">7</span>)      <span style="color:#f92672">|</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">|</span>  bn1                   <span style="color:#f92672">|</span>  <span style="color:#ae81ff">0.1</span>K                <span style="color:#f92672">|</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">|</span>   bn1<span style="color:#f92672">.</span>weight           <span style="color:#f92672">|</span>   (<span style="color:#ae81ff">64</span>,)              <span style="color:#f92672">|</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">|</span>   bn1<span style="color:#f92672">.</span>bias             <span style="color:#f92672">|</span>   (<span style="color:#ae81ff">64</span>,)              <span style="color:#f92672">|</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">|</span>  layer1                <span style="color:#f92672">|</span>  <span style="color:#ae81ff">0.2</span>M                <span style="color:#f92672">|</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">|</span>   layer1<span style="color:#ae81ff">.0</span>             <span style="color:#f92672">|</span>   <span style="color:#ae81ff">75.0</span>K              <span style="color:#f92672">|</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">|</span>    layer1<span style="color:#ae81ff">.0</span><span style="color:#f92672">.</span>conv1      <span style="color:#f92672">|</span>    <span style="color:#ae81ff">4.1</span>K              <span style="color:#f92672">|</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">|</span>    layer1<span style="color:#ae81ff">.0</span><span style="color:#f92672">.</span>bn1        <span style="color:#f92672">|</span>    <span style="color:#ae81ff">0.1</span>K              <span style="color:#f92672">|</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">|</span>    layer1<span style="color:#ae81ff">.0</span><span style="color:#f92672">.</span>conv2      <span style="color:#f92672">|</span>    <span style="color:#ae81ff">36.9</span>K             <span style="color:#f92672">|</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">|</span>    layer1<span style="color:#ae81ff">.0</span><span style="color:#f92672">.</span>bn2        <span style="color:#f92672">|</span>    <span style="color:#ae81ff">0.1</span>K              <span style="color:#f92672">|</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">|</span>    layer1<span style="color:#ae81ff">.0</span><span style="color:#f92672">.</span>conv3      <span style="color:#f92672">|</span>    <span style="color:#ae81ff">16.4</span>K             <span style="color:#f92672">|</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">|</span>    layer1<span style="color:#ae81ff">.0</span><span style="color:#f92672">.</span>bn3        <span style="color:#f92672">|</span>    <span style="color:#ae81ff">0.5</span>K              <span style="color:#f92672">|</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">|</span>    layer1<span style="color:#ae81ff">.0</span><span style="color:#f92672">.</span>downsample <span style="color:#f92672">|</span>    <span style="color:#ae81ff">16.9</span>K             <span style="color:#f92672">|</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">|</span>   layer1<span style="color:#ae81ff">.1</span>             <span style="color:#f92672">|</span>   <span style="color:#ae81ff">70.4</span>K              <span style="color:#f92672">|</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">|</span>    layer1<span style="color:#ae81ff">.1</span><span style="color:#f92672">.</span>conv1      <span style="color:#f92672">|</span>    <span style="color:#ae81ff">16.4</span>K             <span style="color:#f92672">|</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">|</span>    layer1<span style="color:#ae81ff">.1</span><span style="color:#f92672">.</span>bn1        <span style="color:#f92672">|</span>    <span style="color:#ae81ff">0.1</span>K              <span style="color:#f92672">|</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">|</span>    layer1<span style="color:#ae81ff">.1</span><span style="color:#f92672">.</span>conv2      <span style="color:#f92672">|</span>    <span style="color:#ae81ff">36.9</span>K             <span style="color:#f92672">|</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">|</span>    layer1<span style="color:#ae81ff">.1</span><span style="color:#f92672">.</span>bn2        <span style="color:#f92672">|</span>    <span style="color:#ae81ff">0.1</span>K              <span style="color:#f92672">|</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">|</span>    layer1<span style="color:#ae81ff">.1</span><span style="color:#f92672">.</span>conv3      <span style="color:#f92672">|</span>    <span style="color:#ae81ff">16.4</span>K             <span style="color:#f92672">|</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">|</span>    layer1<span style="color:#ae81ff">.1</span><span style="color:#f92672">.</span>bn3        <span style="color:#f92672">|</span>    <span style="color:#ae81ff">0.5</span>K              <span style="color:#f92672">|</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">|</span>   layer1<span style="color:#ae81ff">.2</span>             <span style="color:#f92672">|</span>   <span style="color:#ae81ff">70.4</span>K              <span style="color:#f92672">|</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">|</span>    layer1<span style="color:#ae81ff">.2</span><span style="color:#f92672">.</span>conv1      <span style="color:#f92672">|</span>    <span style="color:#ae81ff">16.4</span>K             <span style="color:#f92672">|</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">|</span>    layer1<span style="color:#ae81ff">.2</span><span style="color:#f92672">.</span>bn1        <span style="color:#f92672">|</span>    <span style="color:#ae81ff">0.1</span>K              <span style="color:#f92672">|</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">|</span>    layer1<span style="color:#ae81ff">.2</span><span style="color:#f92672">.</span>conv2      <span style="color:#f92672">|</span>    <span style="color:#ae81ff">36.9</span>K             <span style="color:#f92672">|</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">|</span>    layer1<span style="color:#ae81ff">.2</span><span style="color:#f92672">.</span>bn2        <span style="color:#f92672">|</span>    <span style="color:#ae81ff">0.1</span>K              <span style="color:#f92672">|</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">|</span>    layer1<span style="color:#ae81ff">.2</span><span style="color:#f92672">.</span>conv3      <span style="color:#f92672">|</span>    <span style="color:#ae81ff">16.4</span>K             <span style="color:#f92672">|</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">|</span>    layer1<span style="color:#ae81ff">.2</span><span style="color:#f92672">.</span>bn3        <span style="color:#f92672">|</span>    <span style="color:#ae81ff">0.5</span>K              <span style="color:#f92672">|</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">|</span>  layer2                <span style="color:#f92672">|</span>  <span style="color:#ae81ff">1.2</span>M                <span style="color:#f92672">|</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">|</span>   layer2<span style="color:#ae81ff">.0</span>             <span style="color:#f92672">|</span>   <span style="color:#ae81ff">0.4</span>M               <span style="color:#f92672">|</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">|</span>    layer2<span style="color:#ae81ff">.0</span><span style="color:#f92672">.</span>conv1      <span style="color:#f92672">|</span>    <span style="color:#ae81ff">32.8</span>K             <span style="color:#f92672">|</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">|</span>    layer2<span style="color:#ae81ff">.0</span><span style="color:#f92672">.</span>bn1        <span style="color:#f92672">|</span>    <span style="color:#ae81ff">0.3</span>K              <span style="color:#f92672">|</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">|</span>    layer2<span style="color:#ae81ff">.0</span><span style="color:#f92672">.</span>conv2      <span style="color:#f92672">|</span>    <span style="color:#ae81ff">0.1</span>M              <span style="color:#f92672">|</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">|</span>    layer2<span style="color:#ae81ff">.0</span><span style="color:#f92672">.</span>bn2        <span style="color:#f92672">|</span>    <span style="color:#ae81ff">0.3</span>K              <span style="color:#f92672">|</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">|</span>    layer2<span style="color:#ae81ff">.0</span><span style="color:#f92672">.</span>conv3      <span style="color:#f92672">|</span>    <span style="color:#ae81ff">65.5</span>K             <span style="color:#f92672">|</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">|</span>    layer2<span style="color:#ae81ff">.0</span><span style="color:#f92672">.</span>bn3        <span style="color:#f92672">|</span>    <span style="color:#ae81ff">1.0</span>K              <span style="color:#f92672">|</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">|</span>    layer2<span style="color:#ae81ff">.0</span><span style="color:#f92672">.</span>downsample <span style="color:#f92672">|</span>    <span style="color:#ae81ff">0.1</span>M              <span style="color:#f92672">|</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">|</span>   layer2<span style="color:#ae81ff">.1</span>             <span style="color:#f92672">|</span>   <span style="color:#ae81ff">0.3</span>M               <span style="color:#f92672">|</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">|</span>    layer2<span style="color:#ae81ff">.1</span><span style="color:#f92672">.</span>conv1      <span style="color:#f92672">|</span>    <span style="color:#ae81ff">65.5</span>K             <span style="color:#f92672">|</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">|</span>    layer2<span style="color:#ae81ff">.1</span><span style="color:#f92672">.</span>bn1        <span style="color:#f92672">|</span>    <span style="color:#ae81ff">0.3</span>K              <span style="color:#f92672">|</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">|</span>    layer2<span style="color:#ae81ff">.1</span><span style="color:#f92672">.</span>conv2      <span style="color:#f92672">|</span>    <span style="color:#ae81ff">0.1</span>M              <span style="color:#f92672">|</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">|</span>    layer2<span style="color:#ae81ff">.1</span><span style="color:#f92672">.</span>bn2        <span style="color:#f92672">|</span>    <span style="color:#ae81ff">0.3</span>K              <span style="color:#f92672">|</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">|</span>    layer2<span style="color:#ae81ff">.1</span><span style="color:#f92672">.</span>conv3      <span style="color:#f92672">|</span>    <span style="color:#ae81ff">65.5</span>K             <span style="color:#f92672">|</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">|</span>    layer2<span style="color:#ae81ff">.1</span><span style="color:#f92672">.</span>bn3        <span style="color:#f92672">|</span>    <span style="color:#ae81ff">1.0</span>K              <span style="color:#f92672">|</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">|</span>   layer2<span style="color:#ae81ff">.2</span>             <span style="color:#f92672">|</span>   <span style="color:#ae81ff">0.3</span>M               <span style="color:#f92672">|</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">|</span>    layer2<span style="color:#ae81ff">.2</span><span style="color:#f92672">.</span>conv1      <span style="color:#f92672">|</span>    <span style="color:#ae81ff">65.5</span>K             <span style="color:#f92672">|</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">|</span>    layer2<span style="color:#ae81ff">.2</span><span style="color:#f92672">.</span>bn1        <span style="color:#f92672">|</span>    <span style="color:#ae81ff">0.3</span>K              <span style="color:#f92672">|</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">|</span>    layer2<span style="color:#ae81ff">.2</span><span style="color:#f92672">.</span>conv2      <span style="color:#f92672">|</span>    <span style="color:#ae81ff">0.1</span>M              <span style="color:#f92672">|</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">|</span>    layer2<span style="color:#ae81ff">.2</span><span style="color:#f92672">.</span>bn2        <span style="color:#f92672">|</span>    <span style="color:#ae81ff">0.3</span>K              <span style="color:#f92672">|</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">|</span>    layer2<span style="color:#ae81ff">.2</span><span style="color:#f92672">.</span>conv3      <span style="color:#f92672">|</span>    <span style="color:#ae81ff">65.5</span>K             <span style="color:#f92672">|</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">|</span>    layer2<span style="color:#ae81ff">.2</span><span style="color:#f92672">.</span>bn3        <span style="color:#f92672">|</span>    <span style="color:#ae81ff">1.0</span>K              <span style="color:#f92672">|</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">|</span>   layer2<span style="color:#ae81ff">.3</span>             <span style="color:#f92672">|</span>   <span style="color:#ae81ff">0.3</span>M               <span style="color:#f92672">|</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">|</span>    layer2<span style="color:#ae81ff">.3</span><span style="color:#f92672">.</span>conv1      <span style="color:#f92672">|</span>    <span style="color:#ae81ff">65.5</span>K             <span style="color:#f92672">|</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">|</span>    layer2<span style="color:#ae81ff">.3</span><span style="color:#f92672">.</span>bn1        <span style="color:#f92672">|</span>    <span style="color:#ae81ff">0.3</span>K              <span style="color:#f92672">|</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">|</span>    layer2<span style="color:#ae81ff">.3</span><span style="color:#f92672">.</span>conv2      <span style="color:#f92672">|</span>    <span style="color:#ae81ff">0.1</span>M              <span style="color:#f92672">|</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">|</span>    layer2<span style="color:#ae81ff">.3</span><span style="color:#f92672">.</span>bn2        <span style="color:#f92672">|</span>    <span style="color:#ae81ff">0.3</span>K              <span style="color:#f92672">|</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">|</span>    layer2<span style="color:#ae81ff">.3</span><span style="color:#f92672">.</span>conv3      <span style="color:#f92672">|</span>    <span style="color:#ae81ff">65.5</span>K             <span style="color:#f92672">|</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">|</span>    layer2<span style="color:#ae81ff">.3</span><span style="color:#f92672">.</span>bn3        <span style="color:#f92672">|</span>    <span style="color:#ae81ff">1.0</span>K              <span style="color:#f92672">|</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">|</span>  layer3                <span style="color:#f92672">|</span>  <span style="color:#ae81ff">7.1</span>M                <span style="color:#f92672">|</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">|</span>   layer3<span style="color:#ae81ff">.0</span>             <span style="color:#f92672">|</span>   <span style="color:#ae81ff">1.5</span>M               <span style="color:#f92672">|</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">|</span>    layer3<span style="color:#ae81ff">.0</span><span style="color:#f92672">.</span>conv1      <span style="color:#f92672">|</span>    <span style="color:#ae81ff">0.1</span>M              <span style="color:#f92672">|</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">|</span>    layer3<span style="color:#ae81ff">.0</span><span style="color:#f92672">.</span>bn1        <span style="color:#f92672">|</span>    <span style="color:#ae81ff">0.5</span>K              <span style="color:#f92672">|</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">|</span>    layer3<span style="color:#ae81ff">.0</span><span style="color:#f92672">.</span>conv2      <span style="color:#f92672">|</span>    <span style="color:#ae81ff">0.6</span>M              <span style="color:#f92672">|</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">|</span>    layer3<span style="color:#ae81ff">.0</span><span style="color:#f92672">.</span>bn2        <span style="color:#f92672">|</span>    <span style="color:#ae81ff">0.5</span>K              <span style="color:#f92672">|</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">|</span>    layer3<span style="color:#ae81ff">.0</span><span style="color:#f92672">.</span>conv3      <span style="color:#f92672">|</span>    <span style="color:#ae81ff">0.3</span>M              <span style="color:#f92672">|</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">|</span>    layer3<span style="color:#ae81ff">.0</span><span style="color:#f92672">.</span>bn3        <span style="color:#f92672">|</span>    <span style="color:#ae81ff">2.0</span>K              <span style="color:#f92672">|</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">|</span>    layer3<span style="color:#ae81ff">.0</span><span style="color:#f92672">.</span>downsample <span style="color:#f92672">|</span>    <span style="color:#ae81ff">0.5</span>M              <span style="color:#f92672">|</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">|</span>   layer3<span style="color:#ae81ff">.1</span>             <span style="color:#f92672">|</span>   <span style="color:#ae81ff">1.1</span>M               <span style="color:#f92672">|</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">|</span>    layer3<span style="color:#ae81ff">.1</span><span style="color:#f92672">.</span>conv1      <span style="color:#f92672">|</span>    <span style="color:#ae81ff">0.3</span>M              <span style="color:#f92672">|</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">|</span>    layer3<span style="color:#ae81ff">.1</span><span style="color:#f92672">.</span>bn1        <span style="color:#f92672">|</span>    <span style="color:#ae81ff">0.5</span>K              <span style="color:#f92672">|</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">|</span>    layer3<span style="color:#ae81ff">.1</span><span style="color:#f92672">.</span>conv2      <span style="color:#f92672">|</span>    <span style="color:#ae81ff">0.6</span>M              <span style="color:#f92672">|</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">|</span>    layer3<span style="color:#ae81ff">.1</span><span style="color:#f92672">.</span>bn2        <span style="color:#f92672">|</span>    <span style="color:#ae81ff">0.5</span>K              <span style="color:#f92672">|</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">|</span>    layer3<span style="color:#ae81ff">.1</span><span style="color:#f92672">.</span>conv3      <span style="color:#f92672">|</span>    <span style="color:#ae81ff">0.3</span>M              <span style="color:#f92672">|</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">|</span>    layer3<span style="color:#ae81ff">.1</span><span style="color:#f92672">.</span>bn3        <span style="color:#f92672">|</span>    <span style="color:#ae81ff">2.0</span>K              <span style="color:#f92672">|</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">|</span>   layer3<span style="color:#ae81ff">.2</span>             <span style="color:#f92672">|</span>   <span style="color:#ae81ff">1.1</span>M               <span style="color:#f92672">|</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">|</span>    layer3<span style="color:#ae81ff">.2</span><span style="color:#f92672">.</span>conv1      <span style="color:#f92672">|</span>    <span style="color:#ae81ff">0.3</span>M              <span style="color:#f92672">|</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">|</span>    layer3<span style="color:#ae81ff">.2</span><span style="color:#f92672">.</span>bn1        <span style="color:#f92672">|</span>    <span style="color:#ae81ff">0.5</span>K              <span style="color:#f92672">|</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">|</span>    layer3<span style="color:#ae81ff">.2</span><span style="color:#f92672">.</span>conv2      <span style="color:#f92672">|</span>    <span style="color:#ae81ff">0.6</span>M              <span style="color:#f92672">|</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">|</span>    layer3<span style="color:#ae81ff">.2</span><span style="color:#f92672">.</span>bn2        <span style="color:#f92672">|</span>    <span style="color:#ae81ff">0.5</span>K              <span style="color:#f92672">|</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">|</span>    layer3<span style="color:#ae81ff">.2</span><span style="color:#f92672">.</span>conv3      <span style="color:#f92672">|</span>    <span style="color:#ae81ff">0.3</span>M              <span style="color:#f92672">|</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">|</span>    layer3<span style="color:#ae81ff">.2</span><span style="color:#f92672">.</span>bn3        <span style="color:#f92672">|</span>    <span style="color:#ae81ff">2.0</span>K              <span style="color:#f92672">|</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">|</span>   layer3<span style="color:#ae81ff">.3</span>             <span style="color:#f92672">|</span>   <span style="color:#ae81ff">1.1</span>M               <span style="color:#f92672">|</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">|</span>    layer3<span style="color:#ae81ff">.3</span><span style="color:#f92672">.</span>conv1      <span style="color:#f92672">|</span>    <span style="color:#ae81ff">0.3</span>M              <span style="color:#f92672">|</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">|</span>    layer3<span style="color:#ae81ff">.3</span><span style="color:#f92672">.</span>bn1        <span style="color:#f92672">|</span>    <span style="color:#ae81ff">0.5</span>K              <span style="color:#f92672">|</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">|</span>    layer3<span style="color:#ae81ff">.3</span><span style="color:#f92672">.</span>conv2      <span style="color:#f92672">|</span>    <span style="color:#ae81ff">0.6</span>M              <span style="color:#f92672">|</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">|</span>    layer3<span style="color:#ae81ff">.3</span><span style="color:#f92672">.</span>bn2        <span style="color:#f92672">|</span>    <span style="color:#ae81ff">0.5</span>K              <span style="color:#f92672">|</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">|</span>    layer3<span style="color:#ae81ff">.3</span><span style="color:#f92672">.</span>conv3      <span style="color:#f92672">|</span>    <span style="color:#ae81ff">0.3</span>M              <span style="color:#f92672">|</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">|</span>    layer3<span style="color:#ae81ff">.3</span><span style="color:#f92672">.</span>bn3        <span style="color:#f92672">|</span>    <span style="color:#ae81ff">2.0</span>K              <span style="color:#f92672">|</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">|</span>   layer3<span style="color:#ae81ff">.4</span>             <span style="color:#f92672">|</span>   <span style="color:#ae81ff">1.1</span>M               <span style="color:#f92672">|</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">|</span>    layer3<span style="color:#ae81ff">.4</span><span style="color:#f92672">.</span>conv1      <span style="color:#f92672">|</span>    <span style="color:#ae81ff">0.3</span>M              <span style="color:#f92672">|</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">|</span>    layer3<span style="color:#ae81ff">.4</span><span style="color:#f92672">.</span>bn1        <span style="color:#f92672">|</span>    <span style="color:#ae81ff">0.5</span>K              <span style="color:#f92672">|</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">|</span>    layer3<span style="color:#ae81ff">.4</span><span style="color:#f92672">.</span>conv2      <span style="color:#f92672">|</span>    <span style="color:#ae81ff">0.6</span>M              <span style="color:#f92672">|</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">|</span>    layer3<span style="color:#ae81ff">.4</span><span style="color:#f92672">.</span>bn2        <span style="color:#f92672">|</span>    <span style="color:#ae81ff">0.5</span>K              <span style="color:#f92672">|</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">|</span>    layer3<span style="color:#ae81ff">.4</span><span style="color:#f92672">.</span>conv3      <span style="color:#f92672">|</span>    <span style="color:#ae81ff">0.3</span>M              <span style="color:#f92672">|</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">|</span>    layer3<span style="color:#ae81ff">.4</span><span style="color:#f92672">.</span>bn3        <span style="color:#f92672">|</span>    <span style="color:#ae81ff">2.0</span>K              <span style="color:#f92672">|</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">|</span>   layer3<span style="color:#ae81ff">.5</span>             <span style="color:#f92672">|</span>   <span style="color:#ae81ff">1.1</span>M               <span style="color:#f92672">|</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">|</span>    layer3<span style="color:#ae81ff">.5</span><span style="color:#f92672">.</span>conv1      <span style="color:#f92672">|</span>    <span style="color:#ae81ff">0.3</span>M              <span style="color:#f92672">|</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">|</span>    layer3<span style="color:#ae81ff">.5</span><span style="color:#f92672">.</span>bn1        <span style="color:#f92672">|</span>    <span style="color:#ae81ff">0.5</span>K              <span style="color:#f92672">|</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">|</span>    layer3<span style="color:#ae81ff">.5</span><span style="color:#f92672">.</span>conv2      <span style="color:#f92672">|</span>    <span style="color:#ae81ff">0.6</span>M              <span style="color:#f92672">|</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">|</span>    layer3<span style="color:#ae81ff">.5</span><span style="color:#f92672">.</span>bn2        <span style="color:#f92672">|</span>    <span style="color:#ae81ff">0.5</span>K              <span style="color:#f92672">|</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">|</span>    layer3<span style="color:#ae81ff">.5</span><span style="color:#f92672">.</span>conv3      <span style="color:#f92672">|</span>    <span style="color:#ae81ff">0.3</span>M              <span style="color:#f92672">|</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">|</span>    layer3<span style="color:#ae81ff">.5</span><span style="color:#f92672">.</span>bn3        <span style="color:#f92672">|</span>    <span style="color:#ae81ff">2.0</span>K              <span style="color:#f92672">|</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">|</span>  layer4                <span style="color:#f92672">|</span>  <span style="color:#ae81ff">15.0</span>M               <span style="color:#f92672">|</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">|</span>   layer4<span style="color:#ae81ff">.0</span>             <span style="color:#f92672">|</span>   <span style="color:#ae81ff">6.0</span>M               <span style="color:#f92672">|</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">|</span>    layer4<span style="color:#ae81ff">.0</span><span style="color:#f92672">.</span>conv1      <span style="color:#f92672">|</span>    <span style="color:#ae81ff">0.5</span>M              <span style="color:#f92672">|</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">|</span>    layer4<span style="color:#ae81ff">.0</span><span style="color:#f92672">.</span>bn1        <span style="color:#f92672">|</span>    <span style="color:#ae81ff">1.0</span>K              <span style="color:#f92672">|</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">|</span>    layer4<span style="color:#ae81ff">.0</span><span style="color:#f92672">.</span>conv2      <span style="color:#f92672">|</span>    <span style="color:#ae81ff">2.4</span>M              <span style="color:#f92672">|</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">|</span>    layer4<span style="color:#ae81ff">.0</span><span style="color:#f92672">.</span>bn2        <span style="color:#f92672">|</span>    <span style="color:#ae81ff">1.0</span>K              <span style="color:#f92672">|</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">|</span>    layer4<span style="color:#ae81ff">.0</span><span style="color:#f92672">.</span>conv3      <span style="color:#f92672">|</span>    <span style="color:#ae81ff">1.0</span>M              <span style="color:#f92672">|</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">|</span>    layer4<span style="color:#ae81ff">.0</span><span style="color:#f92672">.</span>bn3        <span style="color:#f92672">|</span>    <span style="color:#ae81ff">4.1</span>K              <span style="color:#f92672">|</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">|</span>    layer4<span style="color:#ae81ff">.0</span><span style="color:#f92672">.</span>downsample <span style="color:#f92672">|</span>    <span style="color:#ae81ff">2.1</span>M              <span style="color:#f92672">|</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">|</span>   layer4<span style="color:#ae81ff">.1</span>             <span style="color:#f92672">|</span>   <span style="color:#ae81ff">4.5</span>M               <span style="color:#f92672">|</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">|</span>    layer4<span style="color:#ae81ff">.1</span><span style="color:#f92672">.</span>conv1      <span style="color:#f92672">|</span>    <span style="color:#ae81ff">1.0</span>M              <span style="color:#f92672">|</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">|</span>    layer4<span style="color:#ae81ff">.1</span><span style="color:#f92672">.</span>bn1        <span style="color:#f92672">|</span>    <span style="color:#ae81ff">1.0</span>K              <span style="color:#f92672">|</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">|</span>    layer4<span style="color:#ae81ff">.1</span><span style="color:#f92672">.</span>conv2      <span style="color:#f92672">|</span>    <span style="color:#ae81ff">2.4</span>M              <span style="color:#f92672">|</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">|</span>    layer4<span style="color:#ae81ff">.1</span><span style="color:#f92672">.</span>bn2        <span style="color:#f92672">|</span>    <span style="color:#ae81ff">1.0</span>K              <span style="color:#f92672">|</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">|</span>    layer4<span style="color:#ae81ff">.1</span><span style="color:#f92672">.</span>conv3      <span style="color:#f92672">|</span>    <span style="color:#ae81ff">1.0</span>M              <span style="color:#f92672">|</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">|</span>    layer4<span style="color:#ae81ff">.1</span><span style="color:#f92672">.</span>bn3        <span style="color:#f92672">|</span>    <span style="color:#ae81ff">4.1</span>K              <span style="color:#f92672">|</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">|</span>   layer4<span style="color:#ae81ff">.2</span>             <span style="color:#f92672">|</span>   <span style="color:#ae81ff">4.5</span>M               <span style="color:#f92672">|</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">|</span>    layer4<span style="color:#ae81ff">.2</span><span style="color:#f92672">.</span>conv1      <span style="color:#f92672">|</span>    <span style="color:#ae81ff">1.0</span>M              <span style="color:#f92672">|</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">|</span>    layer4<span style="color:#ae81ff">.2</span><span style="color:#f92672">.</span>bn1        <span style="color:#f92672">|</span>    <span style="color:#ae81ff">1.0</span>K              <span style="color:#f92672">|</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">|</span>    layer4<span style="color:#ae81ff">.2</span><span style="color:#f92672">.</span>conv2      <span style="color:#f92672">|</span>    <span style="color:#ae81ff">2.4</span>M              <span style="color:#f92672">|</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">|</span>    layer4<span style="color:#ae81ff">.2</span><span style="color:#f92672">.</span>bn2        <span style="color:#f92672">|</span>    <span style="color:#ae81ff">1.0</span>K              <span style="color:#f92672">|</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">|</span>    layer4<span style="color:#ae81ff">.2</span><span style="color:#f92672">.</span>conv3      <span style="color:#f92672">|</span>    <span style="color:#ae81ff">1.0</span>M              <span style="color:#f92672">|</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">|</span>    layer4<span style="color:#ae81ff">.2</span><span style="color:#f92672">.</span>bn3        <span style="color:#f92672">|</span>    <span style="color:#ae81ff">4.1</span>K              <span style="color:#f92672">|</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">|</span>  fc                    <span style="color:#f92672">|</span>  <span style="color:#ae81ff">2.0</span>M                <span style="color:#f92672">|</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">|</span>   fc<span style="color:#f92672">.</span>weight            <span style="color:#f92672">|</span>   (<span style="color:#ae81ff">1000</span>, <span style="color:#ae81ff">2048</span>)       <span style="color:#f92672">|</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">|</span>   fc<span style="color:#f92672">.</span>bias              <span style="color:#f92672">|</span>   (<span style="color:#ae81ff">1000</span>,)            <span style="color:#f92672">|</span>
</span></span></code></pre></div><p>The reason why I also attached a table of <code>ResNet-50</code> model is that I want to point out the fact that the storage usage of <code>CenterPoint</code> is less than that of <code>ResNet-50</code>.</p>
<p>From my perspective, it (may) be common that LiDAR-based 3D object detection model&rsquo;s storage usage is smaller than traditional 2D model, since LiDAR-based 3D object detection model&rsquo;s 3D backbone are using <code>spconv</code> module, a module that take the sparsity nature of <code>Conv3d</code> into consideration and therefore reduce the model storage usage, GPU memory usage and inference time. So it makes sense that from a perspective of storage usage, 3D &lt; 2D.</p>
<p>Back to our original topic, from the first table, we can clearly see that <code>backbone_2d</code> is the most storage-consuming layer, which means we can start from quantization of <code>Conv2d</code> initially.</p>
<h4 id="6-quantization-of-the-model">6. Quantization of the model<a hidden class="anchor" aria-hidden="true" href="#6-quantization-of-the-model">#</a></h4>
<p>Here we try both dynamic and static PTQ only on <code>Conv2d</code>, i.e., have some calibration data flowed within the model, so that the quantizer can get a good idea of the dynamic range of the activation.</p>
<ul>
<li>Original results:</li>
</ul>
<p><img loading="lazy" src="https://s2.loli.net/2024/04/10/LCseIKUgzdkn6wO.png" alt="image-20240409190524483"  />
</p>
<ul>
<li>dynamic calibration-max quantization results:</li>
</ul>
<p><img loading="lazy" src="https://s2.loli.net/2024/04/10/q1tSFTdDs9GLvyY.png" alt="image-20240409190656395"  />
</p>
<p>with model layer&rsquo;s <code>amax</code> is dynamic:</p>
<p><img loading="lazy" src="https://s2.loli.net/2024/04/10/CImiz5W28lVox1T.png" alt="image-20240409201708976"  />
</p>
<ul>
<li>static calibration-max quantization results:</li>
</ul>
<p><img loading="lazy" src="https://s2.loli.net/2024/04/10/vHEbYtsScC62oex.png" alt="image-20240409201528341"  />
</p>
<p>with model layer&rsquo;s <code>amax</code> is a specific range or number:</p>
<p><img loading="lazy" src="https://s2.loli.net/2024/04/10/8ouyWlFiJgTOXSf.png" alt="image-20240409201614153"  />
</p>
<ul>
<li>Weight-only quantization:</li>
</ul>
<p><img loading="lazy" src="https://s2.loli.net/2024/04/11/dhSwfc7nK4tlePz.png" alt="image-20240411100939381"  />
</p>
<p>with model input quantizer&rsquo;s <code>num_bits</code> is 16-bit:</p>
<p><img loading="lazy" src="https://s2.loli.net/2024/04/11/WqntYjaBdmOyi2L.png" alt="image-20240411101044026"  />
</p>
<h4 id="7-conclusion">7. Conclusion<a hidden class="anchor" aria-hidden="true" href="#7-conclusion">#</a></h4>
<p>We can clearly see that the results are only effected a little bit on the basis that we only quantized 2D conv (But this can be due to the optimization of <code>pytorch-quantization</code>). So I think our potential next target will be the <code>spconv</code> layer. Based on the documentation of the <code>pytorch-quantization</code>, we can customize our own quantized layer just like below:
<img loading="lazy" src="https://s2.loli.net/2024/04/10/T1OlILuQUpxS4oh.png" alt="image-20240409204640050"  />
</p>


  </div>

  <footer class="post-footer">
    <ul class="post-tags">
      <li><a href="https://banghao.live/tags/meeting-discussions/">Meeting-Discussions</a></li>
      <li><a href="https://banghao.live/tags/research/">Research</a></li>
      <li><a href="https://banghao.live/tags/quantization/">Quantization</a></li>
    </ul>
<nav class="paginav">
  <a class="prev" href="https://banghao.live/blog/5/">
    <span class="title">« Prev</span>
    <br>
    <span>Meeting Discussion (5)</span>
  </a>
  <a class="next" href="https://banghao.live/blog/3/">
    <span class="title">Next »</span>
    <br>
    <span>Meeting Discussion (3)</span>
  </a>
</nav>

  </footer>
</article>
    </main>
    
<footer class="footer">
    <span>&copy; 2024 <a href="https://banghao.live/">Banghao&#39;s Blog</a></span>
    <span>
        Powered by
        <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">Hugo</a> &
        <a href="https://github.com/adityatelange/hugo-PaperMod/" rel="noopener" target="_blank">PaperMod</a>
    </span>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
        <path d="M12 6H0l6-6z" />
    </svg>
</a>

<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>
<script>
    document.querySelectorAll('pre > code').forEach((codeblock) => {
        const container = codeblock.parentNode.parentNode;

        const copybutton = document.createElement('button');
        copybutton.classList.add('copy-code');
        copybutton.innerHTML = 'copy';

        function copyingDone() {
            copybutton.innerHTML = 'copied!';
            setTimeout(() => {
                copybutton.innerHTML = 'copy';
            }, 2000);
        }

        copybutton.addEventListener('click', (cb) => {
            if ('clipboard' in navigator) {
                navigator.clipboard.writeText(codeblock.textContent);
                copyingDone();
                return;
            }

            const range = document.createRange();
            range.selectNodeContents(codeblock);
            const selection = window.getSelection();
            selection.removeAllRanges();
            selection.addRange(range);
            try {
                document.execCommand('copy');
                copyingDone();
            } catch (e) { };
            selection.removeRange(range);
        });

        if (container.classList.contains("highlight")) {
            container.appendChild(copybutton);
        } else if (container.parentNode.firstChild == container) {
            
        } else if (codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName == "TABLE") {
            
            codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(copybutton);
        } else {
            
            codeblock.parentNode.appendChild(copybutton);
        }
    });
</script>
</body>

</html>
